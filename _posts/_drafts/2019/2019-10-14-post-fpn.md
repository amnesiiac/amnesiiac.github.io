---
layout: post
title: "FPN"
subtitle: '原理解析|结合论文分析'
author: "twistfatezz"
header-style: text
# header-img: "img/post-bg-alitrip.jpg"
# header-mask: 0.1
mathjax: true
date: 2019-10-14 19:32 
lang: ch 
catalog: true 
categories: documentation
tags:
  - object detection 
  - Time 2019
---

## Introduction
本文章用于总结关于FPN(Feature Pyramid Networks for Object Detection)文章的思路，并进行一定程度上的解析。FPN论文中的4种region proposal network的基本结构，如下如所示。4个图像包含的信息量很大，每一个图像都对应了一类产生关于输入图像的多尺度特征的经典算法。下面根据4张图像分别简单介绍。

<center><img src="/img/in-post/fpn/structure.png" width="100%"></center>

**(a):Hand-engineered features and early neural networks** 论文中所介绍的早期提取输入图像中的不同尺度特征的方式对应了上图中的a。为什么要提取关于输入图像不同尺度的特征呢? 这其实来源于我们对于人类眼睛识别物体的认知，如上图a，HOG和SIFT首先将输入图像downsample到不同的尺度，一般以2作为downsample rate，然后进一步对于每层得到的downsampled img进行不同方差的`guassian bluring`，从而得到模糊程度不同的图像。这样生成的图像和人眼观察到的事物很相似，不同尺度的图像模拟了人眼观察事物的近大远小，不同形状的高斯模糊模拟了人眼观察事物的清晰度。这就是LOG(Laplassian of Gaussian)图像的原理。更进一步的，我们对于每一组(不同分辨率的图像)进行相邻差分，就得到了能用于SIFT算法的DOG(Difference of Gaussian)图像。更多细节可以参考[这个博客](https://blog.csdn.net/weixin_38404120/article/details/73740612)以及其他文献。根据原文进行对图a进行理解：
> [SIFT] features were originally extracted at scale-space extrema and used for feature point matching. 
> [HOG] features, and later SIFT features as well, were computed densely over entire image pyramids. 
> [Early ConvNets] on face detection computed shallow networks over image pyramids to detect faces across scales.

**(b):Deep ConvNet object detectors** 关于上图中的b，其实对应了利用了单层feature map进行检测的许多算法，如[overfeat](https://openreview.net/forum?id=Hq5MgBFOP62-X#cb1bf585-d8ae-4de7-aa0c-f47cdc763d8d)，[RCNN](/documentation/2019/09/29/post-rcnn/)，[SPPnet](https://arxiv.org/pdf/1406.4729.pdf)，[fast-rcnn](/documentation/2019/10/06/post-fast-rcnn/)以及[faster-rcnn](/documentation/2019/10/06/post-faster-rcnn/)。

**(c):Methods using multiple layers** 近期的许多算法都应用了多层的feature map，想法是通过不同分辨率的feature map上进行特征提取检测能够更好的利用网络结构中的多尺度的信息。相应经典的架构如`FCN`，[Parsenet](https://arxiv.org/pdf/1506.04579.pdf)，[SSD](/documentation/2019/10/04/post-ssd/)，`U-net`。

## FPN
FPN(Feature Pyramid Networks)的结构可以参考论文中的图进行理解。图中的$1\times 1$的conv用于改变`bottom-up`的channel个数，使得跨层连接的feature map之间可以相加。图中的$2\times up$表示对于`top-down`的feature map进行2倍上采样。下面分别对于两个方向的网络模型进行分析：

<center><img src="/img/in-post/fpn/fpn.png" width="60%"></center>

### Bottom-up
**Bottom-up pathway**
> There are often many layers producing output maps of the same size and we say these layers are in the same network stage. We choose the output of the last layer of each stage as our reference set of feature maps. This choice is natural since the deepest layer of each stage should have the strongest features. <br> 
> `explain:`下面贴出了Resnet backbone网络的结构，FPN只连接每个`stage`的最后一个卷积层，即下面表格中的`convn_x`中的最后一个卷积层得到的feature map。作者对此的解释是每个阶段的最后一层有相对最strongest的特征。另外，resnet的每个block内部不改变feature map的大小，只是逐渐增加feature map的channel，而不同的block之间的feature map有两倍的关系。对照FPN结构示意图，我们可以清晰的了解为什么`top-down`需要2x的上采样。

<center><img src="/img/in-post/fpn/backbone.png" width="80%"></center>

### Top-down 
**Top-down pathway and lateral connections**
> The top-down pathway hallucinates higher resolution features by upsampling spatially coarser, but semantically stronger, feature maps from higher pyramid levels. These features are then enhanced with features from the bottom-up pathway via lateral connections. With a coarser-resolution feature map, we upsample the spatial resolution by a factor of 2 (using nearest neighbor upsampling for simplicity) <br>
> `explain:`作者认为，对于FPN中的`top-down`feature map，它们的高层次特征语义非常丰富，然而由于前面使用了大量的卷积，这些层丢失了空间上的语义，因此，对于目标定位或者分割等需要空间语义作为支持的任务而言，使用跨层相加能够将浅层的空间位置语义和深层次的特征语义相加和，达到最好的效果。参考上面的backbone network的结构以及`bottom-up`的选层，我们可以得到上采样的采样率。此外，作者还提供了一种简单可行的上采样的方式：使用最近邻点插值法对feature map进行upsample操作。更详细的关于图像上采样、下采样的介绍可以参考这个[csdn博客](https://blog.csdn.net/stf1065716904/article/details/78450997)。

### Results 
**results on obj detection**
<center><img src="/img/in-post/fpn/result.png" width="80%"></center>

## Code
等待整理...

## Reference
> 参考FPN原论文分析。

> 1 当使用inline数学公式且公式经过GFM排版之后都在同一行 使用`$...$`符号<br>
> 2 当希望数学公式单独成行或者经过GFM排版之后占用多行 应当使用`$$...$$`符号<br>
> 3 对于表示条件概率 需要表示竖线的时候`|` 应当使用`\mid` 而不是直接在键盘上打出`|` => 容易被编辑器认为是一个md制表符<br>
> 4 在md引入图片的时候 不要使用`<center>`和`</center>` 在这篇文档的编辑过程中vscode的preview插件在使用了上述符号之后 导致下一段的数学公式预览显示不正常<br>
> 5 使用md的时候 单独的两段文字上下需要空出一行<br>
> 6 想要强制换行的时候 需要使用`<br>`而不是`<enter>`<br>
> 7 特殊字符如果想要避免和md解析关键字冲突 应当使用``将关键字包含在内