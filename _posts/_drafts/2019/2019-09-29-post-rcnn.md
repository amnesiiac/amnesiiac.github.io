---
layout: post
title: "RCNN"
subtitle: '原理解析|实现思路'
author: "twistfatezz"
header-style: text
# header-img: "img/post-bg-alitrip.jpg"
# header-mask: 0.1
mathjax: true
date: 2019-09-29 20:12 
lang: ch 
catalog: true
categories: documentation 
tags:
  - object detection
  - Time 2019
---

### Introduction
RCNN的全称是：Rich feature hierarchies for accurate oject detection and semantic segmentation。由Ross Girshick在2014年发表。它有许多重要的意义：1 在`Pascal VOC 2012`上，mAP达到53.3%，比原来最好的结果提升了30%。2 对于一个相对较小的数据集`Pascal voc`，可以将在大数据集`imagenet`中训练的模型拿过来进行finetune训练。是RCNN系列的开山之作。

### Preparations
**➀ 目标检测** 目标检测=定位+识别，定位是一个回归的问题，识别是一个分类的问题。<br>
**➁ 特征提取** 传统的图像特征提取的常用方式如`SIFT`、`HOG`详细介绍见[这篇总结]()，不过随着深度学习的发展，`DNN`成为主流。<br>
**➂ 区域生成算法** 以下列举了几个经典的候选区域生成算法：objectness，selective search，category-independen object proposals，constrained parametric min-cuts(CPMC)，multi-scale combinatorial grouping，Ciresan。本文中采用了selective search算法。关于无监督区域生成算法的相应的代码介绍详见[这篇总结](/documentation/2019/10/01/post-region-proposal/)。<br>
**➃ NMS非极大值抑制算法** 关于非最大值抑制算法以及相关改进算法实现详见[这篇总结](/documentation/2019/10/01/post-non-maximum-suppression/)。下面的两组图片来自论文Adaptive NMS: Refining Pedestrian Detection in a Crowd，下图是adaptive NMS算法的展示，可直观理解NMS算法的作用。

<center><img src="/img/in-post/rcnn/nms0.png" width="70%"></center>

<center><img src="/img/in-post/rcnn/nms1.png" width="73%"></center>

如上图所示，prediction before NMS图片中是网络对于所有区域生成算法产生的候选区域，设定NMS阈值为0.5之后，每一轮挑选出confidence最大的bbox，将剩下所有的bbox和它计算IOU，如果IOU>0.5，则认为它们属于同一个物体的不同bbox，将其余bbox(confidence rank)放到需要抑制的bbox集合中。<br>
需要注意的是，**NMS算法并不会参与到RCNN的训练阶段中，而是在test或者validation的时候，使用NMS算法对于SVM产生的所有的proposal中根据bbox的confidence结合bbox之间的IOU进行选择，得到最终的结果**。

### Method
**➀ Inference of RCNN** <br>
**#1** 给定一张输入图片，从图片中提取2000个候选区域(proposal)，区域是类别独立的，区域划分采用无监督的算法生成。<br>
**#2** 对于每个区域利用Alexnet抽取一个固定长度的特征向量。<br>
**#3** 对每个区域利用SVM进行目标分类。可以参考论文中的原图进行理解：

<center><img src="/img/in-post/rcnn/rcnn_flow.png" width="75%"></center>

**#4** RCNN中应用的Alexnet结构图如下，单GPU模型版本，和原论文中的有所不同：

<center><img src="/img/in-post/rcnn/alexnet.png" width="90%"></center>

**➁ RCNN的流程对应的算法模块简介** <br>
**#1** 使用selective search算法生成类别独立的候选区域，这些候选区域其中包含了RCNN最终proposal定位的位置信息(后面会详细介绍)。<br>
**#2** 为了能够满足Alexnet统一输入尺度(包括各向同性各向异性尺度变换)，对于候选区域进行尺度调整，可参考原文进行理解：

> 这个变换有很多办法，我们使用了最简单的一种。无论候选区域是什么尺寸和宽高比，我们都把候选框变形成想要的尺寸。具体的，变形之前，我们现在候选框周围加上16的padding，再进行各向异性缩放。这种形变使得mAP提高了3到5个百分点。在补充材料中，作者对比了各向异性和各向同性缩放缩放方法。

**#3 在Pascal voc数据集上finetune Alexnet** 针对训练过程，有以下几点需要注意：<br>
**#3-1** finetune alexnet的时候正负样本怎么定义，正负样本如何产生？<br>
将selective search步骤中产生的2000个region proposal和所有20+1个类别的ground truth进行IOU计算(当前图片没有这个类别则无需计算)，只要当前proposal和任意一个类别的IOU>0.5，则看作正样本，剩余的proposal作负样本看待。<br>
**#3-2** 如何finetune Alexnet？<br>
RCNN中的的alexnet是一个20+1分类的问题，训练的时候，batch\_size=128，其中96个负样本(类别不限制)，32个正样本，正负样本比例为1:3，样本的label就是20+1个分类的label，采用SGD进行finetune，初始学习率为0.001。最后将训练好的神经网络去掉最后4096->21的分类层，前面的所有层参数保留作为"特征提取器"来使用，用这个"特征提取器"对每个候选区域提取固定长度的特征向量(特征向量是4096维，候选区域2000个，所以Alexnet的输出是一个2000x4096的矩阵)。参考原文进行理解：

> We treat all region proposals with $IOU>=0.5$ overlap with a ground-truth box as positives for that box’s class and the rest as negatives. In each SGD iteration, we uni- formly sample 32 positive windows (over all classes) and 96 background windows to construct a mini-batch of size 128. We bias the sampling towards positive windows because they are extremely rare compared to background. <br>

> To review the definitions briefly, for fine-tuning we map each object proposal to the ground-truth instance with which it has maximum IoU overlap (if any) and label it as a positive for the matched ground-truth class if the IoU is at least 0.5. All other proposals are labeled “back- ground” (i.e., negative examples for all classes). 

**#4 使用一系列的SVM分类器对于提取的特征向量进行分类** 对于Alexnet产生的2000个特征向量，每一个特征向量都输入到SVM进行训练(每个SVM做2分类，针对Pascal voc数据集20+1分类的问题，训练21个SVM)。

> For training SVMs, in contrast, we take only the ground-truth boxes as positive examples for their respective classes and label proposals with less than 0.3 IoU overlap with all instances of a class as a negative for that class. Proposals that fall into the grey zone (more than 0.3 IoU overlap, but are not ground truth) are ignored.

**#5 RCNN训练流程中的要点解析** <br>
**问题一**：为什么不直接使用finetune之后的Alexnet模型直接用于分类检测呢？为什么需要将特征向量输入到SVM中再进行分类？参见原文：

> It would be cleaner to simply apply the last layer of the fine-tuned network, which is a 21-way softmax regression classifier, as the object detector. We tried this and found that performance on VOC 2007 dropped from 54.2% to 50.9% mAP.

**问题二**：如何理解Alexnet中和ground\_truth的IOU>=0.5的proposal就作为正样本，其他的部分作为负样本，而训练SVM的时候只有ground\_truth作为正样本，而和ground\_truth的IOU<=0.3的作为负样本，介于两者之间的不予考虑？<br>
解释：Alexnet的部分属于"初步特征提取阶段"，设置的正例比较"宽松"的原因是想要尽可能多的获取检测目标的特征，可以适当引入一些其他无关特征，属于"粗粒度的特征提取部分"。而SVM需要对于每个proposal进行进行confidence打分，需要尽可能的为"有效区域"进行打分，对于无关区域不打分，属于"精细例度的特征表示阶段"。

**#6 bbox regression** 关于边界框回归这一块需要详细整理，推导，因为后面许多文章做bbox regression都是引用了这种编码的方式，例如[faster rcnn](/documentation/2019/10/06/post-faster-rcnn/), [ssd](/documentation/2019/10/04/post-ssd/)，ssd稍有不同：采用了3x3的kernel得到encode的参数，而rcnn采用pool5特征的线性函数获得encode(下文中的$t_{\*}$)参数。

训练过程中，我们最初选择的region proposal可以作为当前物体的proposal\_bbox的基础，为了能够让proposal\_bbox和ground\_truth边框更加接近，论文中采用了bbox regression的步骤对于proposal的边框进行微调，向ground\_truth bbox做回归。bbox回归的形象表示如下：

<center><img src="/img/in-post/rcnn/bbox_regression.png" width="20%"></center>

**#6-1** 边框回归的目的是：给定$(x_{proposal},y_{proposal},w_{proposal},h_{proposal})$寻找一种映射$f$，使得$f(x_{proposal},y_{proposal},w_{proposal},h_{proposal})=(x_{finetune},y_{finetune},w_{finetune},h_{finetune})$，并且$(x_{finetune},y_{finetune},w_{finetune},h_{finetune})\approx(x_{groundtruth},y_{groundtruth},w_{groundtruth},h_{groundtruth})$。<br>
其中**proposal**表示selective search产生的bbox的中心点$x,y$坐标以及bbox的宽度和高度；**finetune**表示经过边框回归之后的数值；**groundtruth**表示gt\_bbox的真实值。

**#6-2** 边框回归包括中心坐标$x,y$和宽高$w,h$尺度变换两部分：<br>
**#6-2-1** 对于中心坐标$x,y$：

$$
\Delta x=x_{proposal}\times f_x(x_{proposal}),\quad \Delta y=y_{proposal}\times f_y(y_{proposal})
$$

$$
x_{finetune}=\Delta x+x_{proposal}, \quad y_{finetune}=\Delta y+y_{proposal}
$$

**#6-2-2** 对于$w,h$的回归：

$$
\Delta w=exp(f_w(w_{proposal})), \quad \Delta h=exp(f_h(h_{proposal}))
$$

$$
w_{finetune}=\Delta w\times w_{proposal}, \quad h_{finetune}=\Delta h\times h_{proposal}
$$

上面的4个映射关系：$f\_x,f\_y,f\_w,f\_h$并不是bbox回归的直接目标，而是回归从bbox到ground\_truth的变换，定义需要回归的四个变换如下：

$$
t_x=\frac{x_{groundtruth}-x_{proposal}}{w_{proposal}} \quad t_y=\frac{y_{groundtruth}-y_{proposal}}{h_{proposal}}
$$

$$
t_w=log(\frac{w_{groundtruth}}{w_{proposal}}) \quad
t_h=log(\frac{h_{groundtruth}}{h_{proposal}})
$$

RCNN希望能够从pool\_5层中的4096维特征向量中学习一种线性映射定义为$t\_x',t\_y',t\_w',t\_h'$，如下面公式所示：

$$
t_x'=\frac{x_{finetune}-x_{proposal}}{w_{proposal}} \quad t_h'=\frac{y_{finetune}-y_{proposal}}{h_{proposal}}
$$

$$
t_w'=log(\frac{w_{finetune}}{w_{proposal}}) \quad
t_h'=log(\frac{h_{finetune}}{h_{proposal}})
$$

其中$\*\_{finetune}$由上面的公式给出，将其代入得到：

$$
t_x'=\frac{x_{proposal}\times f_x(x_{proposal})}{w_{proposal}} \quad t_y'=\frac{y_{proposal}\times f_y(y_{proposal})}{h_{proposal}}
$$

$$
t_w'=f_w(w_{proposal}) \quad t_h'=f_h(h_{proposal})
$$

**文章中定义上面四个变换中的$$f_{*}$$均为关于$$*_{proposal}$$的线性函数，因此四个变换中的前面的关于 $$*_{proposal}$$系数均可以纳入线性系数的一部分。因此，有：**

$$
t_x'=\frac{linear\_func(x_{proposal})}{w_{proposal}} \quad t_y'=\frac{linear\_func(y_{proposal})}{h_{proposal}}
$$

$$
t_w'=linear\_func(w_{proposal}) \quad t_h'=linear\_func(h_{proposal})
$$

我认为，RCNN中定义了$$f_{*}$$为线性函数，然而从上面的推导中，关于$w$，$h$是线性，关于$x$，$y$并不能看作线性，有分母存在。**其实后面真正做回归的时候利用了$t_{*}'$是线性函数**。

另外，$t_x'\approx t_x,t_y'\approx t_y,t_w'\approx t_w,t_h'\approx t_h$，等价于：

$$
(x_{finetune},y_{finetune},w_{finetune},h_{finetune})\approx(x_{groundtruth},y_{groundtruth},w_{groundtruth},h_{groundtruth})
$$

我们如何才能够得到$t_x',t_y',t_w',t_h'$呢？RCNN的做法是：**将Pool\_5层的4096维度特征向量进行线性变换得到我们想要的微调变换**。定义Pool_5层的特征向量为$\phi_5(v_{proposal})$，那么$t_x',t_y',t_w',t_h'$可以表示成如下形式(想要的微调变换=特征向量的线性变换)：

$$
t_{*}'=w_{*}^{T}\cdot \phi_{5}(v_{proposal}),\ *可以是x,y,w,h.
$$

定义$$t_{*}'$$预测和真实值$$t_{*}$$误差：

$$
Loss=\sum_{i}^{N}(t_{*}^{i}-w_{*}^{T}\cdot \phi_{5}(v_{proposal}^{i}))^2,\ *可以是x,y,w,h.
$$

加入参数的l2正则化，并写出bbox中变换$t$回归的目标函数：

$$
W_{*}=\underset{w}{argmin_{*}}\sum_{i}^{N}(t_{*}^{i}-w_{*}^{T}\cdot \phi_{5}(v_{proposal}^{i}))^2 + \lambda\mid\mid \hat w_{*}\mid\mid ^2, \\ *可以是x,y,w,h. \quad N是训练中的batchsize.
$$

使用梯度下降或者最小二乘法可以求解最佳的$w\_{*}$。用于预测的时候会，使用训练好的Alexnet产生特征向量，在和训练集合中训练好的bbox调整系数相乘，根据上面的公式即可得到测试回归bbox数值$$*_{predict}$$。

关于bbox regression的注意事项见原文：
>  The first is that regularization is important: we set = 1000 based on a validation set. The second issue is that care must be taken when selecting which training pairs (P, G) to use. Intuitively, if P is far from all ground-truth boxes, then the task of transforming P to a ground-truth box G does not make sense. Therefore, we only learn from a proposal P if it is nearby at least one ground-truth box. We implement “nearness” by assigning P to the ground-truth box G with which it has maximum IoU overlap (in case it overlaps more than one) if and only if the overlap is greater than a threshold (which we set to 0.6 using a validation set)

所以，当proposal bbox和ground truth bbox满足上面的条件时，才利用这组(P,G)训练bbox回归模型，否则舍弃这组数据。原因大概是：**bbox regression模块对于proposal的bbox只做微调，不做"大幅度的"调整，我觉得这种bbox regression的实现方式对于bbox的修正能力十分有限，如果做大幅度的调整，误差会很大，而且容易将原本proposed的挺好的bbox弄的乱七八糟。所以作者这样做是想要对于bbox regression的训练加入"人为正则"，将问题narrow down，容易获得比较精确的结果。**我个人不赞同网上传的很厉害的"P和G距离很远的使用是非线性，距离近就是线性"，我觉得线性和非线性和距离没有关系。


### Code
项目代码待整理...


### Reference
> https://blog.csdn.net/zijin0802034/article/details/77685438 <br>
> http://caffecn.cn/?/question/160 <br>


> 1 当使用inline数学公式且公式经过GFM排版之后都在同一行 使用`$...$`符号<br>
> 2 当希望数学公式单独成行或者经过GFM排版之后占用多行 应当使用`$$...$$`符号<br>
> 3 对于表示条件概率 需要表示竖线的时候`|` 应当使用`\mid` 而不是直接在键盘上打出`|` => 容易被编辑器认为是一个md制表符<br>
> 4 在md引入图片的时候 不要使用`<center>`和`</center>` 在这篇文档的编辑过程中vscode的preview插件在使用了上述符号之后 导致下一段的数学公式预览显示不正常<br>
> 5 使用md的时候 单独的两段文字上下需要空出一行<br>
> 6 想要强制换行的时候 需要使用`<br>`而不是`<enter>`<br>
> 7 特殊字符如果想要避免和md解析关键字冲突 应当使用``将关键字包含在内
