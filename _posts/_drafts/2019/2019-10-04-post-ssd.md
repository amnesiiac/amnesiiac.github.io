---
layout: post
title: "SSD"
subtitle: 'SSD实现原理解析|主干部分代码实现'
author: "twistfatezz"
header-style: text
# header-img: "img/post-bg-alitrip.jpg"
# header-mask: 0.1
mathjax: true
date: 2019-10-04 00:21 
lang: ch 
catalog: true
categories: documentation 
tags:
  - object detection 
  - Time 2019
---

### Introduction
Single Shot Object Detector(SSD)属于one-stage模型，相比two-stage模型如[RCNN](/documentation/2019/09/29/post-rcnn/)，[fast-RCNN](/documentation/2019/10/06/post-fast-rcnn/)，[faster-RCNN](/documentation/2019/10/06/post-faster-rcnn/)系列有着更高的检测速度(fps)，相比其他one-stage模型如[yolo](/documentation/2019/10/08/post-yolo/)有着更高的检测精度(mAP)。

one-stage和two-stage的区别：是否通过算法预先进行region proposal的操作。two-stage就是region proposal+classification+regression，one-stage中的SSD框架不使用region proposal，而是对于每一层选定的feature map中的每一个cell做了一些**臆想**的bbox，通过使用3x3的卷积操作，将给出**臆想**的bbox的confidence以及回归的坐标变换的参数。根据confidence以及计算iou数值判断当前这个**臆想**的bbox中到底有没有我们想要的物体。

最后，SSD的核心特点是：对于网络backbone中不同层次的多个feature map都为最终的bbox提供信息，每层feature map提供的信息分别对应多尺度proposal bbox。

SSD的基本结构框图：

<center><img src="/img/in-post/ssd/structure.png" width="100%"></center>

### Preparation
**➀ default box(anchor in faster rcnn)** <br>
default box是输入图像中**假想了**一些固定了大小、位置以及长宽比例的矩形区域，每个default box都对应SSD网络中的一个输出对应(一个输出包含分类任务的confidence以及定位任务的4个回归变换参数)。

**➁ default box的大小** <br>
是由输出位于网络的哪一层决定的，位于网络越深的层，在上面的default box的面积越大，这和[感受野计算](/documentation/2019/10/03/post-compute-receptive-field/)方式有关，但SSD中default box scale的设计并不是严格按照不同层关于输入层的比例拟定的。SSD论文中对于default box的大小的定义如下，其中$m=6,\ s_{min}=0.2,\ s_{max}=0.9$。$k$表示用于产生confidence score以及location params的特征层的编号，结合上面结构框图很容易理解。

$$
s_{k}=s_{\min }+\frac{s_{\max}-s_{\min}}{m-1}(k-1), \quad k \in[1, m]
$$

**➂ aspect ratios** <br>
如果每一层只能定义同一种大小的正方形default box，显然不能够满足对于长宽比例多种多样的目标检测问题的需要，因此，我们还需要在上面结构图中不同的feature map中定义一些不同比例的default box。定义每一层feature map的aspect ratio如下$$a_r\in \left\{1,2,3,\frac{1}{2},\frac{1}{3} \right\}$$，因此每个default box的width，height由下式决定：$$
w_{k}^{a}=s_k \sqrt{ar}, \quad h_{k}^a=s_k \sqrt{ar}
$$。对于$a_r=1$的情况，增加了一种边长为$s_k=\sqrt{s_k s_{k+1}}$的方形default box。

**➃ default box mapping** <br>
下图展示了对于每一层feature map中的cell上定义的default box，如何映射回输入图像相应的位置。按照下面的公式将每个cell的**归一化中心的位置**映射回输入图像(其中$f_k$是第$k$个feature map的大小):

$$
(\frac{i+0.5}{f_k}, \frac{j+0.5}{f_k})
$$

然后和根据每层feature map中定义的aspect ratio以及scale定义位于输入图像上的default box的大小。至此default box在原图像上的位置大小已经确定，相当于RCNN中region proposal的步骤已经完成。

<center><img src="/img/in-post/ssd/mapping.png" width="60%"></center>

**➄ 为什么一张输入图片有8732个default box** <br>
结合上面的SSD网络结构图进行分析：conv4_3中38x38的feature map通过3x3的卷积层预测4个不同宽高比的box，conv7中19x19预测6个，conv8_2, conv9_2预测6个不同长宽比的default box，conv10_2，conv11_2预测4个。所以:

$$
38\times38\times 4+19\times 19\times 6+10\times 10\times 6+5\times 5\times 6+3\times 3\times 4+4=8732
$$

**➅ SSD中的bbox regression是如何encode和decode的** <br>
SSD中的bounding box的编码方式同RCNN系列是一样的，关于bbox的编码方式的推导详见[RCNN文章中method中bbox regression部分](/documentation/2019/09/29/post-rcnn/)，在本文后面SSD损失函数分析的章节有关于SSD中的regression公式和RCNN的regression公式的对照说明。另外可以参考本文中**SSD损失函数定义分析**部分，以及SSD原论文中的说明：

> Similar to Faster R-CNN, we regress to offsets for the center $(cx, cy)$ of the default bounding box $(d)$ and for its width $(w)$ and height $(h)$.

**➆ SSD中正负样本如何定义** <br>
对于每一个sample输入，SSD都能根据不同的feature map，不同的aspect ratio，不同的feature map中的位置给出总共8732个default box(候选位置)，SSD定义和映射回原图的default box如果和ground truth box的IOU(jaccard overlap)>0.5的就作为正样本，其他的都可以当作负样本，这样负样本将远远多于正样本的数量。为了能够保证训练快速收敛，在构建SSD的loss的时候，需要限制正负样本的比例大于1:3，其中对于所有的负样本按照它们的confidence loss进行排序，选取confidence loss最大top_k用于计算confidence loss。后面的损失函数中的Pos和Neg都是按照此定义选取的。下面可以参考原论文进行精确理解。
> During training we need to determine which default boxes correspond to a ground truth detection and train the network accordingly. For each ground truth box we are selecting from default boxes that vary over location, aspect ratio, and scale. We begin by matching each ground truth box to the default box with the best jaccard overlap. <br> 
> After the matching step, most of the default boxes are negatives, especially when the number of possible default boxes is large. This introduces a significant imbalance between the positive and negative training examples. Instead of using all the negative examples, we sort them using the highest confidence loss for each default box and pick the top ones so that the ratio between the negatives and positives is at most 3:1. We found that this leads to faster optimization and a more stable training.

**➇ SSD损失函数定义分析** <br>
总损失函数定义($\alpha$参数经过cross-validation验证取1最好)：

$$
L(x, c, l, g)=\frac{1}{N}\left(L_{\operatorname{conf}}(x, c)+\alpha L_{loc}(x, l, g)\right)
$$

其中bbox regression对应的损失函数如下，我们只需要回归positive bounding box，对于和ground truth不匹配的bbox丢弃。

$$
L_{loc}(x,l,g)=\sum_{i \in Pos}^{N} \sum_{m \in\{c x, c y, w, h\}} x_{i j}^{k} \operatorname{smooth}_{\mathrm{L} 1}\left(l_{i}^{m}-\hat{g}_{j}^{m}\right) 
$$

$$
\hat{g}_{j}^{c x}=\left(g_{j}^{c x}-d_{i}^{c x}\right) / d_{i}^{w} \quad \hat{g}_{j}^{c y}=\left(g_{j}^{c y}-d_{i}^{c y}\right) / d_{i}^{h}
$$

$$
\hat{g}_{j}^{w}=\log \left(\frac{g_{j}^{w}}{d_{i}^{w}}\right) \quad \hat{g}_{j}^{h}=\log \left(\frac{g_{j}^{h}}{d_{i}^{h}}\right)
$$

上面的公式和[RCNN文章中method中bbox regression部分](/documentation/2019/09/29/post-rcnn/)换汤不换药，网络直接学习的不是bbox的位置坐标，而是学习从default box(proposal bbox)到predict bbox(finetune bbox)的一种变换参数，变换参数由$\hat{g}_j^{*}$表示。上面公式中的$\hat{g}_j^{cx},\hat{g}_j^{cy},\hat{g}_j^{w},\hat{g}_j^{h}$相当于RCNN推导中的$t_x',t_t',t_w',t_h'$。注意bbox regression只计算positive bbox的坐标转化参数损失。

用于分类的confidence损失函数的定义如下，对于和ground truth bbox匹配的default box(Pos)相应的confidence输出，和非背景类做交叉熵计算；对于和gt bbox不匹配的default bbox(Neg)，和背景分类计算交叉熵损失。

$$
L_{conf}(x, c)=-\sum_{i \in Pos}^{N} x_{ij}^{p} \log \left(\hat{c}_{i}^{p}\right)-\sum_{i \in N e g} \log \left(\hat{c}_{i}^{0}\right), \quad \text {where} \ \hat{c}_{i}^{p}=\frac{\exp \left(c_{i}^{p}\right)}{\sum_{p} \exp \left(c_{i}^{p}\right)}
$$

**➈ 为什么SSD在实际应用中对于大目标检测结果较好** <br>
通过实践经验得到(使用tensorboard对训练中的网络各层参数更新进行监控)，对于深度神经网络，最后面的层往往对于结果的好坏影响更大；仔细观察训练过程中(如1epoch, 2epoch, 3epoch...)中的模型的在不同层中的表现，浅层的特征在训练初期参数会学习更新，但是随着训练的进行，浅层的参数会处于一种微小的波动中，基本不怎么出现大的波动，但是深层的网络由于总是受到**更加明确的**反传梯度的影响，往往是模型最后准确率上升的**主要贡献者**。因此对于SSD，随着网络训练，整个模型更愿意将最后几层feature map(对应大目标检测)的参数学习的较浅层更加**贴近真实**。

### Model Analysis
**SSD的网络结构解析** SSD的网络结构如上图所示，比较简单。关于构建细节详见[官方caffe代码](https://github.com/weiliu89/caffe/tree/ssd)。下面整理了tensorflow的SSD实现方式，并且结合原文进行分析。整个顺序按照SSD inference的顺序进行，这样最容易帮助理解整个模型的框架流程。

<span id="return_vgg"> </span>
**➀ vgg-16预训练网络的加载和finetune：[[Code]](#vgg)** <br>
> Our experiments are all based on VGG16, which is pre-trained on the ILSVRC CLS-LOC dataset. 

<span id="return_norm"> </span>
**➁ 改造vgg-16 conv4_3：[[Code]](#norm)** <br>
> Since, as pointed out in [12], conv4_3 has a different feature scale compared to the other layers, we use the L2 normalization technique introduced in [12] to scale the feature norm at each location in the feature map to 20 and learn the scale during back propagation.

<span id="return_atrous"> </span>
**➂ 改造vgg-16 fc6/fc7：[[Code]](#atrous)** <br>
> Similar to DeepLab-Large FOV, we convert fc6 and fc7 to convolutional layers, subsample parameters from fc6 and fc7, change pool5 from 2x2-s2 to 3x3-s1,and use the atrous algorithm to fill the "holes".

<span id="return_ssd"> </span>
**➃ 添加SSD-layer用于产生confidence/loc输出：[[Code]](#ssd)** <br>
> The early network layers are based on a standard architecture used for high quality image classification (truncated before any classification layers), which we will call the base network. We then add auxiliary structure to the network to produce detections with the following key features.

<span id="return_loc"> </span>
**➄ 构建location loss：[[Code]](#loc)** <br>
> The localization loss is a Smooth L1 loss between the predicted box and the ground truth box parameters. Similar to Faster R-CNN, we regress to offsets for the center (cx, cy) of the default bounding box and for its width and height.

<span id="return_confidence"> </span>
**➅ 构建SSD confidence loss：[[Code]](#confidence)** <br>
SSD的网络结构较简单，其核心就在于confidence_loss的构建，理解了confidence_loss，就理解了SSD。confidence_loss构建的麻烦的地方在于需要保证负样本个数小于正样本个数的3倍，并且从负样本的confidence_loss中最大的开始计数。附录中的code严格按照论文描述，分为STEP1-STEP6进行实现。<br>
> After the matching step, most of the default boxes are negatives, especially when the number of possible default boxes is large. This introduces a significant imbalance between the positive and negative training examples. Instead of using all the negative examples, we sort them using the highest confidence loss for each default box and pick the top ones so that the ratio between the negatives and positives is at most 3:1. We found that this leads to faster optimization and a more stable training.

## Code
<span id="vgg"> </span> 
### build vgg
```python
def __download_vgg(self, vgg_dir, progress_hook):
    # Check if the model needs to be downloaded
    vgg_archive = 'vgg.zip'
    vgg_files = [vgg_dir + '/vgg/variables/variables.data-00000-of-00001',
                    vgg_dir + '/vgg/variables/variables.index',
                    vgg_dir + '/vgg/saved_model.pb']
    
    # check if missing some vgg files with some compensation 
    missing_vgg_files = [vgg_file for vgg_file in vgg_files if not os.path.exists(vgg_file)]  
    if missing_vgg_files:
        if os.path.exists(vgg_dir):
            shutil.rmtree(vgg_dir)  # del the dir and sub-dirs
        os.makedirs(vgg_dir)  # remake vgg_dir

        # Download vgg
        url = 'https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/vgg.zip'
        if not os.path.exists(vgg_archive):
            if callable(progress_hook):
                urlretrieve(url, vgg_archive, progress_hook)
            else:
                with DLProgress(unit='B', unit_scale=True, miniters=1) as pbar:
                    urlretrieve(url, vgg_archive, pbar.hook)

        # Extract vgg
        zip_archive = zipfile.ZipFile(vgg_archive, 'r')  # construct a zip-file object mode=read
        zip_archive.extractall(vgg_dir)  # extract all file into vgg_dir
        zip_archive.close()

def __load_vgg(self, vgg_dir):
    sess = self.session
    tf.saved_model.loader.load(sess, ['vgg16'], vgg_dir + '/vgg')
    self.image_input = sess.graph.get_tensor_by_name('image_input:0')  # <tf.Tensor 'image_input:0' shape=(?, ?, ?, 3) dtype=float32>
    self.keep_prob = sess.graph.get_tensor_by_name('keep_prob:0')  # <tf.Tensor 'keep_prob:0' shape=<unknown> dtype=float32>
    self.vgg_conv4_3 = sess.graph.get_tensor_by_name('conv4_3/Relu:0')  # <tf.Tensor 'conv4_3/Relu:0' shape=(?, ?, ?, 512) dtype=float32>
    self.vgg_conv5_3 = sess.graph.get_tensor_by_name('conv5_3/Relu:0')  # <tf.Tensor 'conv5_3/Relu:0' shape=(?, ?, ?, 512) dtype=float32>
    self.vgg_fc6_w = sess.graph.get_tensor_by_name('fc6/weights:0')  # <tf.Tensor 'fc6/weights:0' shape=(7, 7, 512, 4096) dtype=float32_ref>
    self.vgg_fc6_b = sess.graph.get_tensor_by_name('fc6/biases:0')  # <tf.Tensor 'fc6/biases:0' shape=(4096,) dtype=float32_ref>
    self.vgg_fc7_w = sess.graph.get_tensor_by_name('fc7/weights:0')  # <tf.Tensor 'fc7/weights:0' shape=(1, 1, 4096, 4096) dtype=float32_ref>
    self.vgg_fc7_b = sess.graph.get_tensor_by_name('fc7/biases:0')  # <tf.Tensor 'fc7/biases:0' shape=(4096,) dtype=float32_ref>
    # build up l2-loss for the chosen layers
    layers = ['conv1_1', 'conv1_2', 'conv2_1', 'conv2_2', 'conv3_1',
                'conv3_2', 'conv3_3', 'conv4_1', 'conv4_2', 'conv4_3',
                'conv5_1', 'conv5_2', 'conv5_3']
    for l in layers:
        self.l2_loss += sess.graph.get_tensor_by_name(l + '/L2Loss:0')
```
[[Return]](#return_vgg)

<span id="norm"> </span>
### conv4_3 norm
```python
def array2tensor(x, name):
    init = tf.constant_initializer(value=x, dtype=tf.float32)
    tensor = tf.get_variable(name=name, initializer=init, shape=x.shape)
    return tensor

def l2_normalization(x, initial_scale, channels, name):  # x=shape=(?, ?, ?, 512)
    with tf.variable_scope(name):
        scale = array2tensor(x=initial_scale * np.ones(channels), name='scale')  # scale->shape=(channels=512,) init_val=(20...)
        x = scale * tf.nn.l2_normalize(x, axis=-1)  # tf.nn.l2_normalize()->shape=(?, ?, ?, 512) | x.shape=(?, ?, ?, 512)
    return x

def __build_norms(self):  # x, initial_scale, channels, name
    x = l2_normalization(x=self.vgg_conv4_3, initial_scale=20, channels=512, name='l2_norm_conv4_3')
    self.norm_conv4_3 = x
```
[[Return]](#return_norm)

<span id="atrous"> </span> 
### modify fc6 & fc7
```python
def __build_vgg_mods_a_trous(self):
        """
        build(modify) a_trous conv layer to vgg model
        """
        sess = self.session
        self.mod_pool5 = tf.nn.max_pool(self.vgg_conv5_3, ksize=[1, 3, 3, 1], strides=[1, 1, 1, 1], padding='SAME', name='mod_pool5')

        # Modified conv6
        with tf.variable_scope('mod_conv6'):
            # derive orig w&b 
            orig_w, orig_b = sess.run([self.vgg_fc6_w, self.vgg_fc6_b])  # w:(7, 7, 512, 4096) | b:(4096,)
            mod_w = np.zeros((3, 3, 512, 1024))  # init mod_w template (h, w, input_channel, output_channel)
            # init mod w&b template
            mod_b = np.zeros(1024)
            # downsample orig_w & orig_b
            for i in range(1024):
                mod_b[i] = orig_b[4 * i]
                # downsample orig_w in h & w & output_channel
                for h in range(3):
                    for w in range(3):
                        mod_w[h, w, :, i] = orig_w[3 * h, 3 * w, :, 4 * i]  # 3*h=0 3 6 | 3*w=0 3 6

            # init w&b
            w = array2tensor(mod_w, 'filter')
            b = array2tensor(mod_b, 'biases')
            # atrous with rate=6 
            x = tf.nn.atrous_conv2d(value=self.mod_pool5, filters=w, rate=6, padding='SAME')
            x = tf.nn.bias_add(x, b)
            x = tf.nn.relu(x)  # <tf.Tensor 'mod_conv6/BiasAdd:0' shape=(?, ?, ?, 1024) dtype=float32>
            self.mod_conv6 = x  # register mod_con6 feature_map to SSDVGG
            self.l2_loss += tf.nn.l2_loss(w)  # add l2-loss of w to total l2-loss

        # Modified conv7
        with tf.variable_scope('mod_conv7'):
            # Decimate the weights
            orig_w, orig_b = sess.run([self.vgg_fc7_w, self.vgg_fc7_b])  # w: (1, 1, 4096, 4096) | b: (4096,)
            mod_w = np.zeros((1, 1, 1024, 1024))
            mod_b = np.zeros(1024)

            for i in range(1024):
                mod_b[i] = orig_b[4 * i]
                for j in range(1024):
                    mod_w[:, :, j, i] = orig_w[:, :, 4 * j, 4 * i]

            # Build the feature map
            w = array2tensor(mod_w, 'filter')  # init w 
            b = array2tensor(mod_b, 'biases')  # init b 
            x = tf.nn.conv2d(self.mod_conv6, w, strides=[1, 1, 1, 1], padding='SAME')
            x = tf.nn.bias_add(x, b)
            x = tf.nn.relu(x)
            self.mod_conv7 = x  # <tf.Tensor 'mod_conv7/BiasAdd:0' shape=(?, ?, ?, 1024) dtype=float32>
            self.l2_loss += tf.nn.l2_loss(w)
```
[[Return]](#return_atrous)

<span id="ssd"> </span> 
### build ssd layers
```python
    def conv_map(x, size, shape, stride, name, padding='SAME'):  # x=input_tensor | size=output_channels | shape=scale_filter
        with tf.variable_scope(name):
            w = tf.get_variable("filter", shape=[shape, shape, x.get_shape()[3], size],  # define weight
                                initializer=tf.contrib.layers.xavier_initializer())
            b = tf.Variable(tf.zeros(size), name='biases')  # define bias
            x = tf.nn.conv2d(x, w, strides=[1, stride, stride, 1], padding=padding)  # conv
            x = tf.nn.bias_add(x, b)
            x = tf.nn.relu(x)
            l2 = tf.nn.l2_loss(w)
        return x, l2
        
    def __with_loss(self, x, l2_loss):  # register l2_loss & return x
        self.l2_loss += l2_loss
        return x

    def __build_ssd_layers(self):
        stride10 = 1
        padding10 = 'VALID'
        if len(self.preset.maps) >= 7:  # set stride10 to add the 7-th layer...
            stride10 = 2
            padding10 = 'SAME'

        x, l2 = conv_map(x=self.mod_conv7, size=256, shape=1, stride=1, name='conv8_1')
        self.ssd_conv8_1 = self.__with_loss(x, l2)
        x, l2 = conv_map(x=self.ssd_conv8_1, size=512, shape=3, stride=2, name='conv8_2')
        self.ssd_conv8_2 = self.__with_loss(x, l2)
        x, l2 = conv_map(x=self.ssd_conv8_2, size=128, shape=1, stride=1, name='conv9_1')
        self.ssd_conv9_1 = self.__with_loss(x, l2)
        x, l2 = conv_map(x=self.ssd_conv9_1, size=256, shape=3, stride=2, name='conv9_2')
        self.ssd_conv9_2 = self.__with_loss(x, l2)
        x, l2 = conv_map(x=self.ssd_conv9_2, size=128, shape=1, stride=1, name='conv10_1')
        self.ssd_conv10_1 = self.__with_loss(x, l2)
        x, l2 = conv_map(x=self.ssd_conv10_1, size=256, shape=3, stride=stride10, name='conv10_2', padding=padding10)
        self.ssd_conv10_2 = self.__with_loss(x, l2)
        x, l2 = conv_map(x=self.ssd_conv10_2, size=128, shape=1, stride=1, name='conv11_1')
        self.ssd_conv11_1 = self.__with_loss(x, l2)
        x, l2 = conv_map(x=self.ssd_conv11_1, size=256, shape=3, stride=1, name='conv11_2', padding='VALID')
        self.ssd_conv11_2 = self.__with_loss(x, l2)

        if len(self.preset.maps) < 7:
            return

        x, l2 = conv_map(self.ssd_conv11_2, 128, 1, 1, 'conv12_1')
        paddings = [[0, 0], [0, 1], [0, 1], [0, 0]]
        x = tf.pad(x, paddings, "CONSTANT")
        self.ssd_conv12_1 = self.__with_loss(x, l2)
        x, l2 = conv_map(x=self.ssd_conv12_1, size=256, shape=3, stride=1, name='conv12_2', padding='VALID')
        self.ssd_conv12_2 = self.__with_loss(x, l2)
```
[[Return]](#return_ssd)

<span id="loc"> </span>
### build location loss
```python
# Compute the localization loss
with tf.variable_scope('localization_loss'):
    # shape: (batch_size, num_anchors, 4) (x,y,w,h)
    loc_diff = tf.subtract(self.locator, gt_loc)
    # shape: (batch_size, num_anchors, 4)
    loc_loss = smooth_l1_loss(loc_diff)
    # sum up (x,y,w,h) for each sample each anchor | shape: (batch_size, num_anchors)
    loc_loss_sum = tf.reduce_sum(loc_loss, axis=-1)
    # only positive(matched)(obj) anchor_loc_loss is computed | shape: (batch_size, num_anchors)=(?,8732)
    positive_locs = tf.where(positives_mask, loc_loss_sum, tf.zeros_like(loc_loss_sum))
    # Total loss of positive anchors | shape: (batch_size,)=(?,)
    localization_loss = tf.reduce_sum(positive_locs, axis=-1)
    # Total localization loss normalized by the number of positives(matched bbox) per sample | shape: (batch_size,)
    localization_loss = tf.where(tf.equal(positives_num, 0), tf.zeros([batch_size]),
                                 tf.div(localization_loss, positives_num_safe))
    # Mean localization loss for the batch -> (mini-bach-loc-loss/batch_size) = loc_loss per sample | shape: scalar
    self.localization_loss = tf.reduce_mean(localization_loss, name='localization_loss')
```
[[Return]](#return_loc)

<span id="confidence"> </span>
### build confidence loss
```python
with tf.variable_scope('confidence_loss'):
    # STEP1: 
    # compute ce per sample per anchor
    # ce->shape: (batch_size, num_anchors)=(?, 8732)
    ce = tf.nn.softmax_cross_entropy_with_logits_v2(labels=gt_cl, logits=self.logits)

    # STEP2: 
    # compute for positive anchors
    # shape: (batch_size, num_anchors)=(?,8732)
    positives = tf.where(positives_mask, ce, tf.zeros_like(ce))
    # sum-up the pos_ce_loss per sample
    # shape: (batch_size,)
    positives_sum = tf.reduce_sum(positives, axis=-1)

    # STEP3: 
    # compute for negative anchors 
    # shape: (batch_size, num_anchors)
    negatives = tf.where(negatives_mask, ce, tf.zeros_like(ce))
    # sort the negatives matches from higher conf_loss to lower conf_loss
    # tf.nn.top_k()[0] return the value sorted | tf.nn.top_k()[1] return the indexes of sorted value
    # shape: (batch_size, num_anchors)=(?,8732)
    negatives_top = tf.nn.top_k(negatives, self.preset.num_anchors)[0]
    # pos_sample_num:neg_sample_num >= 1:3 | find the max num of neg_samples
    # shape: (batch_size,)
    negatives_num_max = tf.minimum(negatives_num, 3 * positives_num)
    # Transposed vector of maximum negatives per sample
    # shape (batch_size, 1) = [ [neg_num_max0],[neg_num_max1] ... [neg_num_max_batch_size-1] ]
    negatives_num_max_t = tf.expand_dims(negatives_num_max, axis=1)
    # build top-k mask
    # Range tensor: [0, 1, 2, ..., 8732-1]
    # shape: (num_anchors,)
    rng = tf.range(start=0, limit=self.preset.num_anchors, delta=1)
    # shape: (1, num_anchors) = [[0, 1, 2, ....8731]]
    range_row = tf.to_int64(tf.expand_dims(rng, 0))
    # build top-k conf_loss mask using tf.less & broadcast | only conf_loss in top-(three times of pos) are marked true 
    # shape: (batch_size, num_anchors)=(?,8732)
    negatives_max_mask = tf.less(range_row, negatives_num_max_t)
    # mask out non top-k negative conf_loss
    # shape: (batch_size, num_anchors)=(?,8732)
    negatives_max = tf.where(negatives_max_mask, negatives_top, tf.zeros_like(negatives_top))
    # sum-up the "chosen" neg_conf_loss per sample
    # shape: (batch_size,)
    negatives_max_sum = tf.reduce_sum(negatives_max, axis=-1)

    # STEP4: 
    # add up pos_conf_loss & chosen neg_conf_loss
    # shape: (batch_size,)
    confidence_loss = tf.add(positives_sum, negatives_max_sum)

    # STEP5: 
    # divide the sum-up conf_loss by N(positives_num_safe)
    # if N=0(num of positive anchors in 8732 =0) set the loss for the sample=0
    # shape: (batch_size,)
    confidence_loss = tf.where(tf.equal(positives_num, 0), tf.zeros([batch_size]),
                               tf.div(confidence_loss, positives_num_safe))

    # STEP6: 
    # mean confidence loss per sample 
    # shape: scalar
    self.confidence_loss = tf.reduce_mean(confidence_loss, name='confidence_loss')
```
[[Return]](#return_confidence)

## Reference
> waiting for process...

> 1 当使用inline数学公式且公式经过GFM排版之后都在同一行 使用`$...$`符号<br>
> 2 当希望数学公式单独成行或者经过GFM排版之后占用多行 应当使用`$$...$$`符号<br>
> 3 对于表示条件概率 需要表示竖线的时候`|` 应当使用`\mid` 而不是直接在键盘上打出`|` => 容易被编辑器认为是一个md制表符<br>
> 4 在md引入图片的时候 不要使用`<center>`和`</center>` 在这篇文档的编辑过程中vscode的preview插件在使用了上述符号之后 导致下一段的数学公式预览显示不正常<br>
> 5 使用md的时候 单独的两段文字上下需要空出一行<br>
> 6 想要强制换行的时候 需要使用`<br>`而不是`<enter>`<br>
> 7 特殊字符如果想要避免和md解析关键字冲突 应当使用``将关键字包含在内
