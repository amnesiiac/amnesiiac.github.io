---
layout: post
title: "ECG Component Analysis"
subtitle: 'An novel structure for ECG analysis'
author: "twistfatezz"
header-style: text
# header-img: "img/post-bg-alitrip.jpg"
# header-mask: 0.1
mathjax: true
date: 2019-11-17 16:16 
lang: ch 
catalog: true 
categories: documentation
tags:
  - ECG
  - Time 2019
---
## Abstract
目标：构建网络结构，在训练好的1d网络模型基础上，通过网络结构改变实现对于任意长度心电信号的成分分析，即给定一段心电信号输入，输出这段心电信号的AAMI种类占比。
方法：采用MIT-BIH arrhythmia database中的心电数据进行实验，利用已经训练好的1d心电基本分类模型进行实验，设计嫁接之后网络结构backbone，实现成分分析的任务需求。
结果：采用设计的结构，实现了对于任意时间的心电信号的输入成分分析，相比逐段分类分析的框架，整个模型的分析性能有很大提升，模型整体的复杂度降低了接近4倍，而且单词成分分析的时间有非常大的提升。
研究意义：本研究设计的网络结构，巧妙的利用了1d心电信号分类分析模型作为基础，通过网络结构中构建一个可以"数据流转置"的结构实现了任意长度心电信号成分分析结构，在不损失分类分析精度的条件下，相比常见的逐段分析模型有着更好的时间效率和模型空间效率，具备了易于部署在移动端设备的特性。

## Introduction
心电信号分析包含有多个层面的任务，如`beat level`，`episode level`，`wave level`，`lead level`等多个层面的分析，其中医生常常根据lead level层面的信息对于病人心脏情况作出宏观的判断，其中的指标涉及到一段心电信号所含有的集中"关注"波形的成分占比。传统的方式采用自下而上的方式，通过分别对于每个接受到的`beat level`的波形进行分析分类，从而得到输入的一整段波形的成分组成。但是，上述常规方式需要对于测试波形进行精确分割处理，虽然常见的beat level分割方式已经达到很好的精度，但是其泛化性能仍然需要得到考证；另外，上述常规方式的数据预处理流程较为繁琐，这也是常规方式分析长时间段心电波形的时间效率低的重要原因；另外，对于移动设别，如果每遇到一个心跳beat就进行一次网络模型的inference，将导致移动应用的耗电的增加。分析上述因素，我们考虑使用一种"集成"的方式处理长时间段的心电信号，即测试的时候，不对每一段信号进行细致分析，通过构建一种巧妙的架构，实现模型一次inference分析任意时间段信号。


## Methodology 
关于本研究中所设计1d心电信号网络结构框图，以及相应组合模块结构框图，原理，python-tensorflow代码实现在这部分展开介绍。

### 1D-model
我们实验中采用了在分类任务上非常流行的backbone结构--`residual block v2`堆叠构成。`residual block v2`的结构设计的非常巧妙，采用学习残差的方式，在一定程度上给予整个网络以一种`跨层连接的`正则化，使得梯度能够更好的在深度神经网络之间传播，能够缓解网络过深导致的梯度消失(弥散)的问题。针对一维度心电信号分析处理的问题，我们采用`扁平式`的residual block堆叠的方式进行模型构建，整个网络的层(feature map)，网络中的滤波器(filter)，网络中的pooling结构都使用一维组件构建。其中2D-CNN和1D-CNN的对照框图如下。

2D-CNN框图如下。

<center><img src="/img/in-post/ecg_2/2d.pdf" width="80%"></center>

1D-CNN的简单模型框图如下。

<center><img src="/img/in-post/ecg_2/1d.pdf" width="80%"></center>

1D-CNN适用于对于一维信号进行特征提取，已经在诸多论文中得到了成功的应用。本文采用Residual 1D-CNN作为整个心电成分分析框架的基础。具体采用的Residual 框架结构如下图所示。

<center><img src="/img/in-post/ecg_2/res.pdf" width="40%"></center>

### 1D-model training
构建好1D-model之后，我们需要对于上述模型在MIT-BIH arrhythmia database上进行预训练(pre-training)。预训练采用的数据按照AAMI标准人为进行划分的数据。根据关于MIT-BIH数据库用于心电分类问题领域内部统一的划分标准进行：每个record大约包含有30min的数据，按照前5min数据作为训练数据集，后面的25min(其余部分)作为测试数据集。MIT-BIH arrhythmia database中各个子类别(sub-categroies)对应到AAMI规定的统一种类的mapping表格如下：

<center><img src="/img/in-post/ecg_2/mapping.pdf" width="100%"></center>

按照对应类别之间的label做好mapping之后，用于训练和测试的数据统计如下。

最后需要利用上述划分好的数据进行1D-backbone model的预训练。训练采用Adam Optimizer优化器进行，所有的实验程序的编写均在`Python 3.6.5`环境下进行，采用`tensorflow-gpu`版本深度学习框架构建所描述的模型，关于代码，这部分不做赘述，详见后面Code部分的介绍。

### Transposed-model
我们将所设计的整个网络框架称之为`transposed-model`，因为，为了能够使得整个模型单次inference得到任意长度心电数据的AAMI类别的成分分析结果(即模型输出各个类别的AAMI占比)，在神经网络的数据流中采用了两次数据转置操作。具体两次数据流转置的介绍如下。首先绘制整个transposed的模型框图。

<center><img src="/img/in-post/ecg_2/transpose.pdf" width="40%"></center>

接下来分模块分步骤的对每一个`transposed-model`的模型组件进行详细介绍，并在最后介绍其训练的方式。

「**ECG Chip**」上图中输入的心电信号被重构成`ecg-chip`的形式，具体的ecg chip的数据结构组织如$$(batch\_size=1,height=?,width=512,channel=1)$$，其中`?`表示无须确定的数值，$$batch\_size$$表示同时共享单次网络模型inference的数据批数，我们将这个输入数据的批数固定为1，$height$对于一般的二维度的输出表示图像的高度，然而对于我们输入的一维心电信号片段，$height$表示输入的一段一维心电信号内部含有的beat个数，在实验中，可以采用任意不同长度的心电信号片段作为输入，因此$height$可以不定的数值，具体地，在tensorflow框架下的实现中采用`None`输入到tensor占位符(placeholder)表示；$width$表示单个beat心电信号包含的采样点数，由于本文中的实验采用单一心电导联进行，所以$channel$定义为1。

「**Transform-1**」以5个心电beat为例，介绍此模块的功能。这个`transfromer`结构的作用是将输入的ECG chip从输入的格式$$(batch\_size=1,height=5,width=512,channel=1)$$转化成$$(batch\_size=5,height=1,width=512,channel=1)$$之后，作为后续共享参数的网络部分的输入。这个结构将数据结构转置的目的是，希望一段任意长度(包含了任意个beat)的心电片段中的每一个beat数据块能够共享`1D-model`对于单个beat进行特征提取并分类部分。也就是说，通过这个数据转置结构，实现了一段任意长度的心电信号输入中的每一个beat内部的特征平行提取。

「**1D Pretrained Model**」这部分的模型的结构已经介绍过，这里主要介绍这个sub-model的嵌入方式，训练方式，以及功能。sub-1d-model的功能主要用来对于经过`transform-1`结构模型产生的每个beat进行特征提取，用来提取和类别特异性信息。对于一段心电信号中的每个beat都进行特征提取，所提取出的一维信号特征作为后面`transform-2`结构的输入。

「**Transform-2**」这部分的数据流转置结构将$$(batch\_size=5,height=1,width=?,channel=?)$$转化成$$(batch\_size=1,height=5,width=?,cannel=?)$$，这种数据转化的目的是，通过将一个批次的并行共享参数的数据feature vector转化成一个批次的能够用于2D模型进行联合分析的结构，从而实现单次inference对于整个输入的心电片段中各个分量的成分特征进行建模，从而输出最后的一段心电信号的各个组分的分量占比。


## Code
### 训练部分代码展示
```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
@time:2019/2/11 下午6:02
@author:bigmelon

-> 学习 tfdbg
-> 学习python 单元测试 def test()
-> 学习python doc中进行 >>>
-> 学习tensorflow timeline测试模块
-> 学习python垃圾回收gc_module & objgraph => https://www.cnblogs.com/xybaby/p/7491656.html
-> 掌握包括tf.stop_gradient()函数在内的gradients高阶用法

-> 对于拟合ecg_chip中的N S V F Q5分类的含量的问题 根据precision_summary的计算方法 当预测值介于(-inf,0)&(4,inf)时 分别大概率预测成N/Q => 目前采用softmax方式处理
-> 对于总样本量 N:755237 S:56820 V:57509 F:56030 Q:56354 样本严重不均衡的问题 怎么处理????
-> todo 使用针对不同层使用不同的学习率 在nsvfq分类层使用较大的lr 在前面的resnet1d网络使用较小的lr => completed
-> todo 探究如何使用tensorflow中的early-stop功能找到最佳的模型 =>
-> todo 探究如何设置l2-norm的weight-decay参数  以用来平衡 l2_loss和confidence_loss
-> todo demo5设计出atrous-resnet1d并训练好相应的模型 + ecgnet进行ecg_chip成分分析的实验 和demo4结果进行对比
-> tf.get_default_graph().finalize() | tf.get_default_graph().finalized -> true |

"""

import multiprocessing as mp
import tensorflow as tf
import numpy as np
import argparse
import math
import sys

from tqdm import tqdm
# import time


from ecgnet_v2 import EcgNetV2
from trainingdata import TrainingData
from utils import str2bool, compute_lr, compute_lr_v2, initialize_uninitialized_variables
from summaries_v2 import PrecisionSummary, EcgChipSummary, LossSummary
from namedtuples import *

import os
os.environ['CUDA_VISIBLE_DEVICES'] = '3'
print(os.environ)
config = tf.ConfigProto()
config.gpu_options.allow_growth = True

WIDTH_OF_ECG_CHIP = 5
LENGTH_OF_ECG_CHIP = 512


def main():
    # Parse the command line input
    # more about parser see: https://www.cnblogs.com/zknublx/p/6106343.html
    global chosen_train_ecg_chips, chosen_train_ecg_chips_label, chosen_train_ecg_chips_ratios, \
        chosen_validate_ecg_chips, chosen_validate_ecg_chips_label, chosen_validate_ecg_chips_ratios
    parser = argparse.ArgumentParser(description='Train the EcgNet')

    parser.add_argument('--name', default='/share/donghao/demo4/ecgnet_checkpoint_files_2d_momentum_100', help='project name')

    parser.add_argument('--data-dir', default='/share/donghao/demo3/x_dataset', help='dataset info directory')

    parser.add_argument('--pretrained_model-dir', default='/share/donghao/demo3/trained_models_pb', help='directory for pretrained model')

    parser.add_argument('--epochs', type=int, default=100, help='number of training epochs')  # todo fine-tune

    parser.add_argument('--batch-size', type=int, default=8, help='batch size')  # todo can be a fine-tune parameter for ecgnet-v2

    parser.add_argument('--tensorboard-dir', default='/share/donghao/demo4/tensorboard_files_2d_momentum_100', help='name of the tensorboard data directory')

    parser.add_argument('--checkpoint-interval', type=int, default=1, help='checkpoint interval')

    parser.add_argument('--max-to-keep', type=int, default=3, help='num of checkpoint files max to keep')

    parser.add_argument('--lr_decay_method_switch', type=float, default=1, help='0=piecewise|others=exponential')  # todo fine-tune

    parser.add_argument('--lr-values', type=str, default='0.001;0.0001;0.00001', help='learning rate values')  # todo fine-tune

    parser.add_argument('--lr-boundaries', type=str, default='589160;1178320', help='learning rate change boundaries (in batches)')

    parser.add_argument('--lr-value', type=float, default=0.001, help='initial lr_rate for exponential lr decay computer')

    parser.add_argument('--decay-steps', type=float, default=14729., help='decay_steps=1 epoch')

    parser.add_argument('--decay-rate', type=float, default=0.99, help='decay rate: for 100 epoch -> lr=0.0001')

    parser.add_argument('--momentum', type=float, default=0, help='momentum for the optimizer')  # todo fine-tune 0.9

    parser.add_argument('--adam', type=float, default=1, help='adam optimizer')

    parser.add_argument('--adagrad', type=float, default=0, help='adagrad optimizer')

    parser.add_argument('--rmsprop', type=float, default=0, help='rmsprop optimizer')

    parser.add_argument('--layers-switch-method', type=int, default=0, help='0-50 1-101 2-152 3-200')

    parser.add_argument('--weight-decay', type=float, default=0.00001, help='L2 normalization factor')  # todo fine-tune

    parser.add_argument('--lr-decay', type=float, default=0.001, help='decay to frozen pretrained layers')  # todo fine-tune

    parser.add_argument('--loss-boom', type=float, default=1., help='boom total loss for balancing training')  # todo fine-tune

    parser.add_argument('--confidence-loss-boom', type=float, default=1., help='boom confidence loss for balancing training')  # todo fine-tune

    parser.add_argument('--continue-training', type=str2bool, default='0', help='continue training from the latest checkpoint')

    parser.add_argument('--num-workers', type=int, default=mp.cpu_count(), help='number of parallel generators')  # mp.cpu_count() return the number of cpus

    args = parser.parse_args()

    print('[i] Project name:                 ', args.name)
    print('[i] Data directory:               ', args.data_dir)
    print('[i] pretrained model directory:   ', args.pretrained_model_dir)
    print('[i] epochs:                       ', args.epochs)
    print('[i] Batch size:                   ', args.batch_size)
    print('[i] Tensorboard directory:        ', args.tensorboard_dir)
    print('[i] Checkpoint interval:          ', args.checkpoint_interval)
    print('[i] Checkpoint max2keep:          ', args.max_to_keep)
    print('[i] Learning rate decay switch:   ', args.lr_decay_method_switch)
    print('[i] Learning rate values:         ', args.lr_values)
    print('[i] Learning rate boundaries:     ', args.lr_boundaries)
    print('[i] Learning rate value(init):    ', args.lr_value)
    print('[i] Decay steps:                  ', args.decay_steps)
    print('[i] Decay rate:                   ', args.decay_rate)
    print('[i] Momentum:                     ', args.momentum)
    print('[i] Adam:                         ', args.adam)
    print('[i] Adagrad:                      ', args.adagrad)
    print('[i] Rmsprop:                      ', args.rmsprop)
    print('[i] Depth of network(method):     ', args.layers_switch_method)
    print('[i] Weight decay:                 ', args.weight_decay)
    print('[i] Learning rate decay:          ', args.lr_decay)
    print('[i] Loss boom rate:               ', args.loss_boom)
    print('[i] Confidence Loss boom:         ', args.confidence_loss_boom)
    print('[i] Continue:                     ', args.continue_training)
    print('[i] Number of workers:            ', args.num_workers)

    # Find an existing checkpoint & continue training...
    start_epoch = 0
    if args.continue_training:
        state = tf.train.get_checkpoint_state(checkpoint_dir=args.name, latest_filename=None)
        if state is None:
            print('[!] No network state found in ' + args.name)
            return 1
        # check ckpt path
        ckpt_paths = state.all_model_checkpoint_paths
        if not ckpt_paths:
            print('[!] No network state found in ' + args.name)
            return 1

        # find the latest checkpoint file to go on train-process...
        last_epoch = None
        checkpoint_file = None
        for ckpt in ckpt_paths:
            # os.path.basename return the final component of a path
            # for e66.ckpt.data-00000-of-00001 we got ckpt_num=66
            ckpt_num = os.path.basename(ckpt).split('.')[0][1:]
            try:
                ckpt_num = int(ckpt_num)
            except ValueError:
                continue
            if last_epoch is None or last_epoch < ckpt_num:
                last_epoch = ckpt_num
                checkpoint_file = ckpt

        if checkpoint_file is None:
            print('[!] No checkpoints found, cannot continue!')
            return 1

        metagraph_file = checkpoint_file + '.meta'

        if not os.path.exists(metagraph_file):
            print('[!] Cannot find metagraph', metagraph_file)
            return 1
        start_epoch = last_epoch

    # Create a project directory to hold the checkpoint files
    else:
        metagraph_file = None
        checkpoint_file = None
        try:
            print('[i] Creating directory             {}...'.format(args.name))
            os.makedirs(args.name)
        except IOError as e:
            print('[!]', str(e))
            return 1

    print('[i] Starting at epoch:            ', start_epoch + 1)
    print('[i] Configuring the training data...')
    try:
        td = TrainingData(args.data_dir)
        print('[i] training samples:             ', td.num_train)
        print('[i] validation samples:           ', td.num_valid)
        print('[i] classes:                      ', td.num_classes)
        print('[i] ecg_chip size:                ', f'({td.sample_width}, {td.sample_length})')
    except (AttributeError, RuntimeError) as e:
        print('[!] Unable to load training data:', str(e))
        return 1

    # Create the network
    with tf.Session(config=config) as sess:
        print('[i] Creating the model...')
        n_train_batches = int(math.ceil(td.num_train / args.batch_size))  # 117827/1->14729
        n_valid_batches = int(math.ceil(td.num_valid / args.batch_size))  # 39253/1->4907
        global_step = None
        learning_rate = None

        if start_epoch == 0:
            if args.lr_decay_method_switch == 0:
                lr_values = args.lr_values.split(';')  # list [0.001, 0.0001, 0.00001]
                try:
                    lr_values = [float(x) for x in lr_values]  # convert to float
                except ValueError:
                    print('[!] Learning rate values must be floats')
                    sys.exit(1)

                lr_boundaries = args.lr_boundaries.split(';')   # learning_rate change boundaries = list [320000, 400000]
                try:
                    lr_boundaries = [int(x) for x in lr_boundaries]  # convert to int
                except ValueError:
                    print('[!] Learning rate boundaries must be ints')
                    sys.exit(1)

                ret = compute_lr(lr_values, lr_boundaries)
                learning_rate, global_step = ret  # derive lr g_stp tensor
            else:
                ret = compute_lr_v2(args.lr_value, args.decay_steps, args.decay_rate)
                learning_rate, global_step = ret

        # build ecgnet todo 另外的一种实现多输入共享部分网络参数的方法详见:gan.py中
        net = EcgNetV2(sess, td.preset)  # __init__ ssdvgg net with (session, preset)
        if start_epoch != 0:  # if start training from checkpoint file
            net.build_from_metagraph(metagraph_file, checkpoint_file)
            net.build_optimizer_from_metagraph()
        else:  # else first train the model
            net.build_from_resnet_2d(td.num_classes, args.layers_switch_method)
            net.build_optimizer(set_diff_lr=False,  # if true set diff-lr
                                method=1,  # method=0 -> to-be-verified | method=1 -> set diff-lr
                                lr_decay=args.lr_decay,  # 0.01
                                learning_rate=learning_rate,
                                loss_boom=args.loss_boom,  # 1.
                                confidence_loss_boom=args.confidence_loss_boom,  # 10.
                                weight_decay=args.weight_decay,
                                momentum=args.momentum,
                                adam=args.adam,
                                adagrad=args.adagrad,
                                rmsprop=args.rmsprop,
                                global_step=global_step)

        # init
        initialize_uninitialized_variables(sess)

        # create writer & saver
        summary_writer = tf.summary.FileWriter(args.tensorboard_dir, sess.graph)
        saver = tf.train.Saver(max_to_keep=args.max_to_keep)  # set max_to_keep=2 checkpoints file

        # Summaries - init/restore summary_ops
        restore = start_epoch != 0  # restore from metagraph - True | first train - False

        training_precision = PrecisionSummary(sess, summary_writer, 'train', td.lname2id.keys(), args.batch_size, restore)
        validation_precision = PrecisionSummary(sess, summary_writer, 'valid', td.lname2id.keys(), args.batch_size, restore)

        training_ecg_chips = EcgChipSummary(sess, summary_writer, 'train', td.label_colors, restore)
        validation_ecg_chips = EcgChipSummary(sess, summary_writer, 'valid', td.label_colors, restore)

        training_loss = LossSummary(sess, summary_writer, 'train', td.num_train, restore)  # summary_op | protocol buf merged
        validation_loss = LossSummary(sess, summary_writer, 'valid', td.num_valid, restore)

        # derive the initial snapshot of the network
        net_summary_ops = net.build_summaries(restore)  # merge
        if start_epoch == 0:
            net_summary = sess.run(net_summary_ops)  # run
            summary_writer.add_summary(net_summary, 0)  # add
            summary_writer.flush()  # flush

        # cycle through the epoch (train&validate)
        # -----------------------------------------------------------------------
        print('[i] Training...')
        # if train the first time, start_epoch=0 else start_epoch=last_epoch(from checkpoint file...)
        for e in range(start_epoch, args.epochs):
            # init or refresh summaries sample cache...
            training_ecg_chip_samples = []
            validation_ecg_chip_samples = []

            # Train ->
            # build pipeline tensor
            td.train_iter(process='train', batch_size=args.batch_size, num_epoch=args.epochs)
            description = '[i] Train {:>2}/{}'.format(e + 1, args.epochs)  # epoch_No/total_epoch_No -> e+1/200
            for _ in tqdm(iterable=td.train_tqdm_iter, total=n_train_batches, desc=description, unit='batches'):
                x, y = sess.run(td.train_sample)  # array(?,5,512,1) array(?,5)

                # for x is changed after preprocess_input-func, here construct a placeholder for primary_x
                if len(training_ecg_chip_samples) < 1 and e != 0:
                    chosen_train_ecg_chips = np.copy(x[:3])  # (3,5,512,1)
                    chosen_train_ecg_chips_label = np.copy(y[:3])  # (3,5)

                feed = {net.resnet_2d_input: x, net.labels: y}  # feed_dict
                ratios, batch_loss_dict, _ = sess.run([net.ratios, net.losses, net.train_op], feed_dict=feed)  # array(?,5)

                # add ratios
                if len(training_ecg_chip_samples) < 1 and e != 0:  # add ratios to chosen list
                    chosen_train_ecg_chips_ratios = ratios

                # check
                if math.isnan(batch_loss_dict['confidence']):
                    print('[!] Confidence loss is NaN.')

                # precision
                training_precision.add(values=ratios, ground_truth=y)  # array(?,5) array(?,5)
                training_loss.add(values=batch_loss_dict, num_samples=args.batch_size)  # add loss into training_loss

                # preheat 1 epoch
                if e == 0:
                    continue
                # save 2 pics during 1 train_epoch for tensorboard summary visualization
                if len(training_ecg_chip_samples) < 1:
                    training_ecg_chip_samples.append((chosen_train_ecg_chips,
                                                      chosen_train_ecg_chips_label,
                                                      chosen_train_ecg_chips_ratios[:3]))

            # Validate ->
            # build pipeline tensor
            td.valid_iter(process='validate', batch_size=args.batch_size, num_epoch=args.epochs)
            description = '[i] Valid {:>2}/{}'.format(e + 1, args.epochs)
            for _ in tqdm(iterable=td.valid_tqdm_iter, total=n_valid_batches, desc=description, unit='batches'):
                x, y = sess.run(td.valid_sample)  # array(?,5,512,1) array(?,5)
                # for x is changed after preprocess_input-func, here construct a placeholder for primary_x
                if len(validation_ecg_chip_samples) < 1 and e != 0:
                    chosen_validate_ecg_chips = np.copy(x[:3])  # list[array(1,5,512,1)...]
                    chosen_validate_ecg_chips_label = np.copy(y[:3])  # list[array(1,5)...]

                feed = {net.resnet_2d_input: x, net.labels: y}
                ratios, batch_loss_dict = sess.run([net.ratios, net.losses], feed_dict=feed)

                if len(validation_ecg_chip_samples) < 1 and e != 0:
                    chosen_validate_ecg_chips_ratios = ratios  # list[array(1,5)...]

                validation_precision.add(values=ratios, ground_truth=y)
                validation_loss.add(batch_loss_dict, args.batch_size)

                # if the first epoch, preheat and no summary output
                if e == 0:  # just validating the w&b without running detections or add summaries
                    continue
                # save 3 pics during 1 validate_epoch for tensorboard summary visualization
                if len(validation_ecg_chip_samples) < 1:
                    validation_ecg_chip_samples.append((chosen_validate_ecg_chips,
                                                        chosen_validate_ecg_chips_label,
                                                        chosen_validate_ecg_chips_ratios[:3]))

            # run-add net w&b
            net_summary = sess.run(net_summary_ops)  # run again to derive 'next-step' summary
            summary_writer.add_summary(net_summary, e + 1)  # add again
            # todo loss/precision summary 的命名有问题 -> 需要解决
            # Write summaries
            training_loss.push(e + 1)
            validation_loss.push(e + 1)
            # push precision
            training_precision.push(e + 1, n_train_batches)  # run-add
            validation_precision.push(e + 1, n_valid_batches)  # run-add
            # if e != 0, push & build summaries...
            if e != 0:
                # push ecg_chips_img to summary
                training_ecg_chips.push(e + 1, training_ecg_chip_samples)  # run-add
                validation_ecg_chips.push(e + 1, validation_ecg_chip_samples)  # run-add
            else:
                pass
            # flush all
            summary_writer.flush()

            # save checkpoint
            if (e + 1) % args.checkpoint_interval == 0:
                checkpoint = '{}/e{}.ckpt'.format(args.name, e + 1)
                saver.save(sess, checkpoint)
                print('[i] Checkpoint saved:', checkpoint)

        # save final checkpoint
        checkpoint = '{}/final.ckpt'.format(args.name)
        saver.save(sess, checkpoint)
        print('[i] Checkpoint saved:', checkpoint)

    return 0


if __name__ == '__main__':
    avoid_warning = FILE_SAMPLE_INFO(..., ..., ..., ...)
    sys.exit(main())

```

### 网络结构部分代码展示
```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
@time:2019/2/11 下午3:41
@author:bigmelon

<<< 2d atrous cnn fullfill the functionality of ecgnet v2 >>>

Typical use:
   from tensorflow.contrib.slim.nets import resnet_v2
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from tensorflow.contrib import layers as layers_lib
from tensorflow.contrib.framework.python.ops import add_arg_scope
from tensorflow.contrib.framework.python.ops import arg_scope
from tensorflow.contrib.layers.python.layers import layers
from tensorflow.contrib.layers.python.layers import utils
# todo the initial definition of the resnet_with_slim
from tensorflow.contrib.slim.python.slim.nets import resnet_utils

from tensorflow.python.ops import math_ops
from tensorflow.python.ops import nn_ops
from tensorflow.python.ops import variable_scope

import tensorflow as tf

from utils import smooth_l1_loss
from namedtuples import *

resnet_arg_scope = resnet_utils.resnet_arg_scope
slim = tf.contrib.slim

LENGTH_OF_ECG_CHIP = 512

avoid_warning1 = BLOCK_INFO(..., ...)
avoid_warning2 = UNIT_INFO(..., ...)
avoid_warning3 = LAYER_INFO(..., ...)


class EcgNetV2:
    """
    EcgNet definition -> mention to avoid variable/op name avoid conflict with original name scope
    """

    def __init__(self, session, preset):
        # set some useful paras
        self.preset = preset  # preset_dict include [saved_model_load_tag_string] -> preset['tag_string']='1d_resnet_pb_model'
        self.num_added_convs = preset['num_added_convs']  # this two should be set into the presets
        self.num_added_classifiers = preset['num_added_classifiers']
        #
        self.session = session
        self.__built = False  # build from resnet-1d-50 flag true when net is built
        # init/build name scope
        self.scopes = []
        self.weight_scopes = []  # 应该放在__build_name之前
        self.bias_scopes = []
        # build_from_resnet_2d
        self.num_classes = None
        self.num_vars = None  # num_vars = 5(num_classes)
        self.resnet_2d_input = None
        # build added ecgnet layers
        ...
        # output/logits
        self.logits = None
        self.ratios = None
        self.most_probable_class = None
        # build_optimizer
        self.added_var_list = []
        self.original_var_list = []
        self.none_value_var_list = []
        self.confidence_loss = None
        self.l2_loss = None
        self.loss = None  # l2+conf
        self.losses = None  # loss dict
        self.labels = None
        self.optimizer = None
        self.train_op = None
        # build_from_meta_graph(checkpoint_file)
        ...
        # build_optimizer_from_metagraph(checkpoint_file)
        ...

    def build_from_resnet_2d(self, num_classes, method, a_trous=False):
        """
        [resnet-1d]  Build the model for training based on a pre-define resnet-1d model.

        :param method: range 0-4 for momentum adam adagrad rmsprop
        :param a_trous: whether to use the model of atrous-resnet-1d
        :param num_classes: number of classes
        """
        self.num_classes = num_classes
        self.num_vars = num_classes  # num_var=num_classes
        self.l2_loss = 0  # init l2-loss
        if a_trous:
            self.__build_ecgnet_layers(method=method)
            self.__build_names()  # build network name lists todo shadow is set as False...
            self.__build_l2_loss()  # build l2_loss
        else:
            self.__build_ecgnet_layers(method=method)
            self.__build_names()  # build network name lists todo shadow is set as False...
            self.__build_l2_loss()  # build l2_loss

    def build_optimizer(self, set_diff_lr, method=1, lr_decay=0.01, learning_rate=0.001, loss_boom=1.,
                        confidence_loss_boom=1., weight_decay=0.0005, momentum=0.9, adam=0, adagrad=0,
                        rmsprop=0, global_step=None):
        """
        weight_decay => define the weight_decay according to the ssd's paras, for the scale of ssd_w=513M,
                        for the scale of resnet1d=4.2M(52layer)+0.969Mx5(estimate as 12layer | each layer is 5times of original)
                        let the w*l2_loss be equal -> 513M x 0.0005 = 9.04M x weight_decay
                        => weight_decay=0.028 => set it as 0.01
        momentum => about momentum alpha para set : see deep learning textbook on desktop !
        """
        self.labels = tf.placeholder(dtype=tf.float32, name='labels', shape=[None, self.num_vars])  # (?,5)
        with tf.variable_scope('confidence_loss'):
            confidence_diff = tf.subtract(self.ratios, self.labels)  # (1,5)
            confidence_loss = smooth_l1_loss(confidence_diff)  # (?=1,5)
            self.confidence_loss = tf.multiply(confidence_loss_boom, tf.reduce_sum(confidence_loss, axis=None), name='boomed_loss')

        with tf.variable_scope('l2_loss'):
            self.l2_loss = tf.multiply(weight_decay, self.l2_loss)

        with tf.variable_scope('total_loss'):
            self.loss = tf.multiply(loss_boom, self.l2_loss + self.confidence_loss)

        # todo(2) there's no need using with tf.variable_scope here for losses is totally determined by its components
        self.losses = {
            'total': self.loss,  # ()
            'confidence': self.confidence_loss,  # ()
            'l2': self.l2_loss  # ()
        }

        if set_diff_lr:
            if method == 0:
                # todo ideas to be verified ->>>>
                with tf.variable_scope('optimizer', reuse=None):
                    for _ in tf.trainable_variables():  # len(var)=198
                        if 'added_conv_' in _.name or 'classifier_' in _.name:
                            self.added_var_list.append(_)  # 24
                        else:
                            self.original_var_list.append(_)  # 174
                    # todo find out this can work for other optimizer?????
                    opt1 = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)  # pass lr
                    opt2 = tf.train.GradientDescentOptimizer(learning_rate=learning_rate*0.01)  # set 'frozen' lr-rate
                    grads = tf.gradients(self.loss, self.added_var_list + self.original_var_list)
                    grads1 = grads[:len(self.added_var_list)]
                    grads2 = grads[len(self.added_var_list):]
                    op1 = opt1.apply_gradients(zip(grads1, self.added_var_list), global_step=global_step)
                    op2 = opt2.apply_gradients(zip(grads2, self.original_var_list))
                    optimizer = tf.group(op1, op2)
                    self.optimizer = optimizer
                with tf.control_dependencies([self.optimizer]):
                    self.train_op = tf.no_op(name='context_manager')
            else:
                # according to tf official doc
                with tf.variable_scope('optimizer', reuse=None):
                    for _ in tf.trainable_variables():  # 198
                        if 'added_conv_' in _.name or 'classifier_' in _.name:
                            self.added_var_list.append(_)  # 24
                        elif _.name == 'postnorm/gamma:0' or _.name == 'postnorm/beta:0' or _.name == 'logits/biases:0':
                            self.none_value_var_list.append(_)  # 3
                        else:
                            self.original_var_list.append(_)  # 171
                    if momentum:
                        optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)
                        grads_and_vars = optimizer.compute_gradients(self.loss, var_list=None)  # default to all trainable vars
                        capped_grads_and_vars = [self.__cap_grads(gv, lr_decay) for gv in grads_and_vars]
                        optimizer = optimizer.apply_gradients(grads_and_vars=capped_grads_and_vars,
                                                              global_step=global_step, name='optimizer')
                    elif adam:
                        optimizer = tf.train.AdamOptimizer(learning_rate)
                        grads_and_vars = optimizer.compute_gradients(self.loss,
                                                                     var_list=None)  # default to all trainable vars
                        capped_grads_and_vars = [self.__cap_grads(gv, lr_decay) for gv in grads_and_vars]
                        optimizer = optimizer.apply_gradients(grads_and_vars=capped_grads_and_vars,
                                                              global_step=global_step, name='optimizer')
                    elif adagrad:
                        optimizer = tf.train.AdagradOptimizer(learning_rate)
                        grads_and_vars = optimizer.compute_gradients(self.loss,
                                                                     var_list=None)  # default to all trainable vars
                        capped_grads_and_vars = [self.__cap_grads(gv, lr_decay) for gv in grads_and_vars]
                        optimizer = optimizer.apply_gradients(grads_and_vars=capped_grads_and_vars,
                                                              global_step=global_step, name='optimizer')
                    elif rmsprop:
                        optimizer = tf.train.RMSPropOptimizer(learning_rate)
                        grads_and_vars = optimizer.compute_gradients(self.loss,
                                                                     var_list=None)  # default to all trainable vars
                        capped_grads_and_vars = [self.__cap_grads(gv, lr_decay) for gv in grads_and_vars]
                        optimizer = optimizer.apply_gradients(grads_and_vars=capped_grads_and_vars,
                                                              global_step=global_step, name='optimizer')
                    else:
                        optimizer = None
                        exit("wrong optimizer chosen!")

                self.optimizer = optimizer
                with tf.control_dependencies([self.optimizer]):
                    self.train_op = tf.no_op(name='context_manager')
        else:
            # train with same lr for pretrained/added
            with tf.variable_scope('optimizer', reuse=None):
                if momentum:
                    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)
                    optimizer = optimizer.minimize(self.loss, global_step=global_step, name='optimizer')
                elif adam:
                    optimizer = tf.train.AdamOptimizer(learning_rate)
                    optimizer = optimizer.minimize(self.loss, global_step=global_step, name='optimizer')
                elif adagrad:
                    optimizer = tf.train.AdagradOptimizer(learning_rate)
                    optimizer = optimizer.minimize(self.loss, global_step=global_step, name='optimizer')
                elif rmsprop:
                    optimizer = tf.train.RMSPropOptimizer(learning_rate)
                    optimizer = optimizer.minimize(self.loss, global_step=global_step, name='optimizer')
                else:
                    optimizer = None
                    exit('[!] Wrong optimizer chosen!')
            self.optimizer = optimizer
            with tf.control_dependencies([self.optimizer]):
                self.train_op = tf.no_op(name='context_manager')

    def build_from_metagraph(self, metagraph_file, checkpoint_file):
        """
        [metagraph-1]  Build the model for inference from a metagraph snapshot and weights checkpoint.
        """
        sess = self.session
        saver = tf.train.import_meta_graph(metagraph_file)  # import metagraph
        saver.restore(sess, checkpoint_file)  # restore
        self.resnet_2d_input = sess.graph.get_tensor_by_name('input:0')
        self.logits = sess.graph.get_tensor_by_name('output/Squeeze:0')
        self.ratios = sess.graph.get_tensor_by_name('output/Softmax:0')

    def build_optimizer_from_metagraph(self):
        """
        [metagraph-2]  Get the optimizer and the loss from metagraph
        """
        sess = self.session
        # verified
        self.loss = sess.graph.get_tensor_by_name('total_loss/Mul:0')
        self.confidence_loss = sess.graph.get_tensor_by_name('confidence_loss/boomed_loss:0')
        self.l2_loss = sess.graph.get_tensor_by_name('l2_loss/Mul:0')
        self.optimizer = sess.graph.get_operation_by_name('optimizer/optimizer')  # build optimizer using get op by name
        self.train_op = sess.graph.get_operation_by_name('context_manager')
        self.labels = sess.graph.get_tensor_by_name('labels:0')

        self.losses = {
            'total': self.loss,
            'confidence': self.confidence_loss,
            'l2': self.l2_loss
        }

    def __build_ecgnet_layers(self, method):
        """
        Constructor for 2d-resnet
        #1 tf.contrib.layers.variance_scaling_initializer() <-> relu() is chosen
        #2 tf.contrib.layers.xavier_initializer() <-> tanh() or sigmoid()
        this code can be simplified by using util.conv_map
        """
        self.resnet_2d_input = tf.placeholder(dtype=tf.float32, name='input', shape=[None, self.num_classes, LENGTH_OF_ECG_CHIP, 1])  # (?,5,512,1)
        with slim.arg_scope(resnet_arg_scope(weight_decay=0.0001, batch_norm_decay=0.997,
                                             batch_norm_epsilon=1e-5, batch_norm_scale=True)):
            if method == 0:   # logits=(?,1,1,5) | end_points["predictions"]=shape(?,1,1,5)
                logits, end_points = resnet_v2_50(
                    self.resnet_2d_input, num_classes=self.num_classes, is_training=True, global_pool=True,
                    output_stride=None, reuse=None, scope='resnet_v2_50')
            elif method == 1:
                logits, end_points = resnet_v2_101(
                    self.resnet_2d_input, num_classes=self.num_classes, is_training=True, global_pool=True,
                    output_stride=None, reuse=None, scope='resnet_v2_101')
            elif method == 2:
                logits, end_points = resnet_v2_152(
                    self.resnet_2d_input, num_classes=self.num_classes, is_training=True, global_pool=True,
                    output_stride=None, reuse=None, scope='resnet_v2_152')
            elif method == 3:
                logits, end_points = resnet_v2_200(
                    self.resnet_2d_input, num_classes=self.num_classes, is_training=True, global_pool=True,
                    output_stride=None, reuse=None, scope='resnet_v2_200')
            else:
                logits, end_points = None, None
                exit('[!] Wrong method flag!')
        # todo 'resnet_v2_50/logits/weights:0' shape=(1,1,2048,num_classes) 从2048降到5是不是太快了 是否应该增加几层进行缓冲?
        # shape(1,1,2048,512)
        # with tf.variable_scope('added_conv_1'):  # shape(1,1,512,128)
        #     ...
        # with tf.variable_scope('added_conv_2'):  # shape(1,1,128,5)
        #     ...

        with tf.variable_scope('output'):
            self.logits = tf.squeeze(logits, axis=[1, 2])  # (?,5)
            self.ratios = tf.nn.softmax(logits=self.logits, axis=None)  # (?,5)

        with tf.variable_scope('most_probable_class'):
            self.most_probable_class = tf.argmax(self.ratios, axis=1)  # (?,)

        # set the built_flag = True
        self.__built = True

    def __build_names(self, shadow_var_flag=False):
        """
        Not using shadow variables by default...
        """
        # build total weight/biases scope
        if not shadow_var_flag:
            for _ in tf.trainable_variables():
                if _.name.find('weights') == -1:  # not found
                    pass
                else:
                    self.weight_scopes.append(_)
                if _.name.find('biases') == -1:
                    pass
                else:
                    self.bias_scopes.append(_)
            pass
        else:
            ...
        # build total scope
        self.scopes = self.weight_scopes + self.bias_scopes

    def __build_l2_loss(self):
        for _ in self.weight_scopes:
            self.l2_loss += tf.nn.l2_loss(_)

    def __cap_grads(self, gv, decay):
        """
        gv=grads_and_vars -> tuple | decay='learning_rate_decay' to separate the lr for pretrained / added layers
        """
        if gv[1] in self.added_var_list:
            return gv[0], gv[1]
        elif gv[1] in self.original_var_list:
            try:
                return tf.multiply(decay, gv[0]), gv[1]
            except ValueError:  # catch the value error: none value cannot be convert to tensor
                exit(f'Cannot convert tensor:{gv[1]} which has None value! --> ecgnet.py line 449')
        elif gv[1] in self.none_value_var_list:
            return gv[0], gv[1]
            # <tf.Variable 'postnorm/gamma:0' shape=(128,) dtype=float32_ref>
            # <tf.Variable 'postnorm/beta:0' shape=(128,) dtype=float32_ref>
            # <tf.Variable 'logits/biases:0' shape=(5,) dtype=float32_ref>
        else:
            raise ValueError('Wrong grads & vars input!')

    def build_summaries(self, restore):
        """
        this func is to build summaries for net object params like (weight/bias/etc)
        """
        if restore:  # name verified
            return self.session.graph.get_tensor_by_name('net_summaries/net_summaries:0')

        sess = self.session
        summaries = []
        with tf.variable_scope('filter_summaries'):
            for _ in self.weight_scopes:
                tensor = sess.graph.get_tensor_by_name(_.name)
                summary = tf.summary.histogram(_.name, tensor)
                summaries.append(summary)
        with tf.variable_scope('bias_summaries'):
            for _ in self.bias_scopes:
                tensor = sess.graph.get_tensor_by_name(_.name)
                summary = tf.summary.histogram(_.name, tensor)
                summaries.append(summary)

        # this op creates a [`Summary`] protocol buffer that contains the union of all the values in the input summaries.
        return tf.summary.merge(summaries, name='net_summaries')

```
## Result
首先通过`tensorboard`工具展示在训练过程中，整个成分分析模型在验证集上的收敛过程如下图所示。
<center><img src="/img/in-post/ecg_2/pie.pdf" width="100%"></center>

另外，在构建的测试集上，任意截取心底那片段测试结果如下表示所示，初步展示了成分分析准确度和截取心电片段长度的关系。
<center><img src="/img/in-post/ecg_2/result.pdf" width="100%"></center>

## Reference

> 1 当使用inline数学公式且公式经过GFM排版之后都在同一行 使用`$...$`符号<br>
> 2 当希望数学公式单独成行或者经过GFM排版之后占用多行 应当使用`$$...$$`符号<br>
> 3 对于表示条件概率 需要表示竖线的时候`|` 应当使用`\mid` 而不是直接在键盘上打出`|` => 容易被编辑器认为是一个md制表符<br>
> 4 在md引入图片的时候 不要使用`<center>`和`</center>` 在这篇文档的编辑过程中vscode的preview插件在使用了上述符号之后 导致下一段的数学公式预览显示不正常<br>
> 5 使用md的时候 单独的两段文字上下需要空出一行<br>
> 6 想要强制换行的时候 需要使用`<br>`而不是`<enter>`<br>
> 7 特殊字符如果想要避免和md解析关键字冲突 应当使用``将关键字包含在内