---
layout: post
title: "modern operating system: introduction"
subtitle: '[modern operating system] - chapter1' 
author: "twistfatezz"
header-style: text
# header-img: "img/in-post/economics_1/headimg.png"
# header-mask: 0.8
comments: false 
mathjax: true 
date: 2021-11-04 21:47
lang: ch 
catalog: true 
categories: operating-system 
tags:
  - Time 2021
  - modern operating system 
---
### ä¸€ï¼šå¼•è¨€
##### 1 ä¸ºä»€ä¹ˆéœ€è¦æ“ä½œç³»ç»Ÿ
ç°ä»£è®¡ç®—æœºæ˜¯ä¸€ä¸ªå¤æ‚çš„ç³»ç»Ÿï¼Œå¦‚æœæ¯ä¸ªç¨‹åºå‘˜ä¸å¾—ä¸æŒæ¡æ•´ä¸ªç³»ç»Ÿæ„é€ ç»†èŠ‚æ‰èƒ½ç¼–å†™ä»£ç ï¼Œåˆ™ä¸ºè®¡ç®—æœºç¼–å†™ä»£ç å°†æ˜¯ä¸å¯èƒ½å®Œæˆçš„ä»»åŠ¡ã€‚å¦å¤–ï¼Œå¯¹äºè®¡ç®—æœºç³»ç»Ÿç»„ä»¶è¿›è¡Œç®¡ç†&è°ƒç”¨&ä¼˜åŒ–åŒæ ·æ˜¯ä¸€é¡¹æŒ‘æˆ˜æ€§æå¼ºçš„å·¥ä½œã€‚å› æ­¤ï¼Œè®¡ç®—æœºå®‰è£…äº†ä¸€å±‚è½¯ä»¶ï¼Œç§°ä¸ºæ“ä½œç³»ç»Ÿ(operating system, os)ã€‚osçš„ä½œç”¨æ˜¯ä¸ºç”¨æˆ·ç¨‹åºæä¾›ä¸€ä¸ªæ›´å¥½ã€æ›´ç®€å•ã€æ›´æ¸…æ™°çš„è®¡ç®—æœºæ¨¡å‹ï¼Œå¹¶å€Ÿæ­¤ç®¡ç†è®¡ç®—æœºä¸­çš„åŸºç¡€è®¾æ–½ã€‚

##### 2 è®¡ç®—æœºä¸­è½¯ã€ç¡¬ä»¶çš„åŸºæœ¬ç»„æˆéƒ¨åˆ†ç»“æ„ç®€å›¾
<center><img src="/img/in-post/operating_system_img/os_1_1.pdf" width="80%"></center>

##### 3 å†…æ ¸æ€å’Œç”¨æˆ·æ€
- æ“ä½œç³»ç»Ÿè¿è¡Œåœ¨**å†…æ ¸æ€(kernel mode)**ã€‚è¿è¡Œåœ¨å†…æ ¸æ€çš„oså…·æœ‰å¯¹æ‰€æœ‰ç¡¬ä»¶çš„çš„å®Œå…¨è®¿é—®æƒï¼Œèƒ½å¤Ÿæ‰§è¡Œæœºå™¨æœ¬èº«èƒ½å¤Ÿæ‰§è¡Œçš„ä»»ä½•æŒ‡ä»¤(instruction)ã€‚
- è½¯ä»¶é™¤äº†æ“ä½œç³»ç»Ÿçš„éƒ¨åˆ†è¿è¡Œåœ¨**ç”¨æˆ·æ€ä¸‹(user mode)**ã€‚è¿è¡Œåœ¨ç”¨æˆ·æ€çš„è½¯ä»¶åªä½¿ç”¨äº†æœºå™¨æŒ‡ä»¤çš„ä¸€ä¸ªå­é›†ï¼šé‚£äº›ä¼šå½±å“åˆ°æœºå™¨æ§åˆ¶ã€æˆ–è€…è¿›è¡Œè¾“å…¥è¾“å‡ºæ“ä½œ(I/O)çš„æŒ‡ä»¤åœ¨ç”¨æˆ·æ€æ˜¯ç¦æ­¢ä½¿ç”¨çš„ã€‚
- åµŒå…¥å¼ç³»ç»Ÿ(embedded systems)å¯èƒ½ä¸å…·æœ‰å†…æ ¸æ€ï¼›è§£é‡Šç³»ç»Ÿ(interpreted systems)å¦‚åŸºäºjavaçš„ç³»ç»Ÿé€šè¿‡è§£é‡Šçš„æ–¹å¼è€Œä¸æ˜¯ç¡¬ä»¶æ–¹å¼å¯¹è®¡ç®—æœºç»„ä»¶è¿›è¡ŒåŒºåˆ†ã€‚
- è®¸å¤šç³»ç»Ÿä¸­ï¼Œä¸€äº›åœ¨ç”¨æˆ·æ€è¿è¡Œçš„ç¨‹åºååŠ©æ“ä½œç³»ç»Ÿå®Œæˆä¸€äº›éœ€è¦ç‰¹æƒçš„åŠŸèƒ½ã€‚è¿™ç±»ç³»ç»Ÿä¸­æ— æ³•åˆ’åˆ†æ˜æ˜¾çš„ç•Œé™ã€‚åœ¨å†…æ ¸æ€ä¸­è¿è¡Œçš„å±äºæ“ä½œç³»ç»Ÿä¸­çš„éƒ¨åˆ†ï¼Œä½†æ˜¯ä¸€äº›åœ¨å†…æ ¸å¤–è¿è¡Œçš„ç¨‹åºç”±äºå’Œæ“ä½œç³»ç»Ÿå¯†åˆ‡ç›¸å…³ï¼Œä¹Ÿå¯ä»¥è¢«è®¤ä¸ºæ˜¯æ“ä½œç³»ç»Ÿçš„ä¸€éƒ¨åˆ†(arguably part of os)ã€‚

##### 4 æœ¬æ–‡å†…å®¹æ¦‚è¦
æœ¬æ–‡ä¸»è¦ä»‹ç»æ“ä½œç³»ç»Ÿçš„è‹¥å¹²é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œincludingå®ƒä»¬çš„åŸºæœ¬æƒ…å†µï¼Œå®ƒä»¬çš„å†å²æ²¿é©ï¼Œåˆ†ç±»ï¼Œä»¥åŠæ“ä½œç³»ç»Ÿä¸­çš„ä¸€äº›åŸºæœ¬æ¦‚å¿µåŠå…¶ç»“æ„ã€‚


### äºŒï¼šä»€ä¹ˆæ˜¯æ“ä½œç³»ç»Ÿ
##### 1 æ“ä½œç³»ç»Ÿä½œä¸ºè®¡ç®—æœºä½“ç³»ç»“æ„çš„ä¸€ç§æ‹“å±•(os as an extended machine) - top-down view
> **Why need os?** The architecture (instruction set, memory organization, I/O, and bus structure) of most computers at the machine-language level is primitive and awkward to program, especially for input/output.

> **(i) Operating systems contain many drivers for controlling I/O devices.** Clearly, no sane programmer would want to deal with this disk at the hardware level. Instead, a piece of software, called a **disk driver**, deals with the hardware and provides an interface to read and write disk blocks, without getting into the details. 

> **(ii) All operating systems provide yet another layer of abstraction for using disks: files.** Using this abstraction, programs can create, write, and read files, without having to deal with the messy details of how the hardware actually works.

> **This abstraction is the key to managing all this complexity.** Good abstractions turn a nearly impossible task into two manageable ones. The first is defining and implementing the abstractions. The second is using these abstractions to solve the problem at hand.

##### 2 æ“ä½œç³»ç»Ÿä½œä¸ºèµ„æºç®¡ç†å™¨(os as a resource manager) - bottom-up view
> **ä»è®¡ç®—æœºèµ„æºç®¡ç†è§’åº¦æ¥çœ‹ï¼Œä¸ºä»€ä¹ˆéœ€è¦æ“ä½œç³»ç»Ÿï¼Ÿ** When a computer (or network) has more than one user, the need for managing and protecting the memory, I/O devices, and other resources is even more since the users might otherwise interfere with one another. In addition, users often need to share not only hardware, but information (files, databases, etc.) as well. <br>
> **ç®€è€Œè¨€ä¹‹** In short, this view of the operating system holds that its primary task is to keep track of which programs are using which resource, to grant resource requests, to account for usage, and to mediate conflicting requests from different programs and users.

> **(i) ä»¥è‡ªåº•è€Œä¸Šçš„æ–¹å¼æ¥è§£é‡Šæ“ä½œç³»ç»Ÿå¯¹äºèµ„æºè´¹ç®¡ç†çš„ä½œç”¨** Modern computers consist of processors, memories, timers, disks, mice, network interfaces, printers, and a wide variety of other devices. In the bottom-up view, the job of the operating system is to provide for an orderly and controlled allocation of the processors, memories, and I/O devices among the various programs wanting them.

> **(ii) æ“ä½œç³»ç»Ÿè¿›è¡Œèµ„æºç®¡ç†æ—¶ä½¿ç”¨å¤šè·¯å¤ç”¨æŠ€æœ¯ï¼ŒåŒ…æ‹¬æ—¶é—´ä¸Šçš„å¤ç”¨&ç©ºé—´ä¸Šçš„å¤ç”¨** Resource management includes multiplexing (å¤šè·¯å¤ç”¨, sharing) resources in two different ways: in time and in space. When a resource is time multiplexed, different programs or users take turns using it. First one of them gets to use the resource, then another, and so on.

##### 3 æ“ä½œç³»ç»Ÿçš„å†å²(omitted)

##### 4 è®¡ç®—æœºç¡¬ä»¶ç®€ä»‹
<center><img src="/img/in-post/operating_system_img/os_1_2.pdf" width="100%"></center>

###### 4.1 å¤„ç†å™¨(processors)
> **CPU is the "brain" of the computer**. It fetches instructions from memory and executes them. <br>

**[1] CPUçš„åŸºæœ¬æµç¨‹å¾ªç¯** 
> The basic cycle of every CPU is to fetch the first instruction from memory, decode it to determine its type(ç±»å‹) and operands(æ“ä½œæ•°), execute it, and then fetch, decode, and execute subsequent instructions. The cycle is repeated until the program finishes.

**[2] å…³äºCPUçš„æŒ‡ä»¤é›†** 
> Each CPU has a specific set of instructions that it can execute. Thus an x86 processor cannot execute ARM programs and an ARM processor cannot execute x86 programs. 

**[3] å…³äºCPUä¸­çš„é€šç”¨å¯„å­˜å™¨**
> **ä¸ºä»€ä¹ˆéœ€è¦åœ¨CPUä¸­ä½¿ç”¨å¯„å­˜å™¨** Because accessing memory to get an instruction or data word takes much longer than executing an instruction, all CPUs contain some registers inside to hold key variables and temporary results.
> **æŒ‡ä»¤é›†çš„åŸºæœ¬åŠŸèƒ½** The instruction set generally contains instructions to load a word from memory into a register, and store a word from a register into memory. 

**[4] å…³äºCPUä¸­çš„å‡ ä¸ªå¯¹ç¨‹åºå‘˜å¯è§çš„ä¸“ç”¨å¯„å­˜å™¨** 
> In addition to the general registers used to hold variables and temporary results, most computers have several special registers that are visible to the programmer.  <br>
> **(i) ç¨‹åºè®¡æ•°å™¨** One of these is the **program counter**, which contains the memory address of the next instruction to be fetched. After that instruction has been fetched, the program counter is updated to point to its successor. <br>
> **(ii) å †æ ˆæŒ‡é’ˆ** Another register is the **stack pointer**, which points to the top of the current stack in memory. The stack contains one frame for each procedure that has been entered but not yet exited(è¯¥å †æ ˆåŒ…å«äº†ç¨‹åºæ¯ä¸ªæ‰§è¡Œæ­¥éª¤çš„"æ ˆå¸§"). A procedureâ€™s stack frame holds those input parameters, local variables, and temporary variables that are not kept in registers("æ ˆå¸§"ä¿å­˜äº†å’Œç¨‹åºæ‰§è¡Œç›¸å…³çš„å‚æ•°ã€æœ¬åœ°å˜é‡ã€ä¸´æ—¶å˜é‡ä¿¡æ¯). <br>
> **(iii) ç¨‹åºçŠ¶æ€å­—å¯„å­˜å™¨** Yet another register is the **PSW (Program Status Word)**. This register contains the condition code bits(æ¡ä»¶åˆ¤æ–­bitä½), which are set by comparison instructions(è¢«æ¯”è¾ƒæ“ä½œæŒ‡ä»¤è®¾ç½®), the CPU priority(CPUä¼˜å…ˆçº§), the mode (user or kernel)(è½¯ä»¶è¿è¡ŒçŠ¶æ€ï¼šç”¨æˆ·æ€orå†…æ ¸æ€), and various other control bits(ä»¥åŠå…¶ä»–æ§åˆ¶bitä½). User programs may normally read the entire PSW but typically may write only some of its fields. The PSW plays an important role in system calls and I/O.

**[5] å…³äºCPUçš„3ç§æ¶æ„çš„è®¨è®º** <br> å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå±•ç¤ºäº†3ç§CPUçš„æ¶æ„ç»„ç»‡æ–¹å¼ï¼Œ(a)è¡¨ç¤ºä¸€ä¸ªå°†æ‰€æœ‰åŠŸèƒ½é›†æˆåœ¨ä¸€èµ·çš„CPUï¼›(b)è¡¨ç¤ºCPUçš„æµæ°´çº¿æ¶æ„ï¼›(c)è¡¨ç¤ºsuperscalar CPUæ¶æ„ã€‚ 

<center><img src="/img/in-post/operating_system_img/os_1_3.pdf" width="100%"></center>

> **(1) ç”±äºæ€§èƒ½ä¸Šçš„åŸå› ï¼Œç®€å•é›†æˆæ¶æ„(a)å¾ˆæ—©å°±è¢«æ”¾å¼ƒä½¿ç”¨** To improve performance, CPU designers have long abandoned the simple model of fetching, decoding, and executing one instruction at a time(ç®€å•é›†æˆæ¶æ„ä¸€æ¬¡åªèƒ½å¤„ç†ä¸€æ¡æœºå™¨æŒ‡ä»¤). <br>
> **(2) CPUçš„æµæ°´çº¿æ¶æ„(b)** Many modern CPUs have facilities for executing more than one instruction at the same time. For example, a CPU might have separate fetch, decode, and execute units, so that while it is executing instruction n, it could also be decoding instruction n + 1 and fetching instruction n + 2. Such an organization is called a pipeline. <br>
> **(3) CPUæµæ°´çº¿æ¶æ„å¸¦æ¥çš„é—®é¢˜** **(i)** In most pipeline designs, once an instruction has been fetched into the pipeline, it must be executed, even if the preceding instruction was a conditional branch that was taken(ä¸€æ—¦ä¸€ä¸ªæŒ‡ä»¤è¢«è¯»å–åˆ°æµæ°´çº¿ä¸­ï¼Œå®ƒå¿…é¡»è¢«æ‰§è¡Œï¼Œå³ä½¿è¯¥æŒ‡ä»¤å‰é¢æ˜¯æ¡ä»¶åˆ¤æ–­æ‰§è¡Œè¯­å¥). **(ii)** Pipelines cause compiler writers and operating system writers great headaches because they expose the complexities of the underlying machine to them and they have to deal with them(æµæ°´çº¿CPUæ¶æ„å°†æœºå™¨æœ¬èº«ç¡¬ä»¶åº•å±‚çš„å¤æ‚æ€§æš´éœ²ç»™ç¼–è¯‘å™¨ä½œè€…ã€æ“ä½œç³»ç»Ÿä½œè€…). <br>
> **(4) è¶…æ ‡é‡CPUæ¶æ„çš„ç‰¹æ€§** In this design, multiple execution units are present(åŒæ—¶æ‰§è¡Œå¤šä¸ªæœºå™¨æŒ‡ä»¤), e.g., one for integer arithmetic, one for floating-point arithmetic, and one for Boolean operations. Two or more instructions are fetched at once, decoded, and dumped into a holding buffer until they can be executed(â‰¥2æ¡æœºå™¨æŒ‡ä»¤è¢«åŒæ—¶è¯»å–ã€è§£ç å¹¶é€åˆ°ä¿æŒç¼“å­˜åŒºç­‰å¾…æ‰§è¡Œ). <br>
> **(5) superscalar CPUæ¶æ„å¸¦æ¥çš„é—®é¢˜** An implication of this design is that program instructions are often executed out of order(è¯¥æ¶æ„æ‰§è¡Œæœºå™¨æŒ‡ä»¤ç»å¸¸å¤±åº). For the most part, it is up to the hardware to make sure the result produced is the same one a sequential implementation would have produced(å¤§å¤šæ•°æƒ…å†µï¼Œä¾èµ–ç¡¬ä»¶æ¥ä¿è¯æ‰§è¡Œæ¬¡åºä¸å¤±åº), but an annoying amount of the complexity is foisted onto the operating system, as we shall see(ä½†ä¹Ÿç”±äºè¿™ç§CPUæ¶æ„è€Œå¢åŠ äº†oså®ç°ä¸­çš„å¤æ‚åº¦).

###### 4.2 å¤šçº¿ç¨‹(multithreading) & å¤šæ ¸èŠ¯ç‰‡(multicore chips)
**[1] å…³äºMooreå®šå¾‹**
> **(i) å®šä¹‰** Mooreâ€™s law states that the number of transistors on a chip doubles every 18 months. <br>
> **(ii) Mooreå®šå¾‹çš„è§£é‡Š** This "law" is not some kind of law of physics, like conservation of momentum, but is an observation by Intel cofounder Gordon Moore of how fast process engineers at the semiconductor companies are able to shrink their transistors. <br>
> **(iii) Mooreå®šå¾‹çš„æé™** Mooreâ€™s law has held for over three decades now and is expected to hold for at least one more. After that, the number of atoms per transistor will become too small and quantum mechanics will start to play a big role, preventing further shrinkage of transistor sizes.

**[2] å¦‚ä½•åˆ©ç”¨é€æ¸å¢åŠ çš„æ™¶ä½“ç®¡èµ„æºï¼Ÿ**
> **(i) Bigger caches** One obvious thing to do is put bigger caches on the CPU chip. That is definitely happening, but eventually the point of diminishing returns will be reached. <br>
> **(ii) More complicated control logics** The obvious next step is to replicate not only the functional units, but also some of the control logic. The Intel Pentium 4 introduced this property, called â®multithreadingâ¯ or â®hyperthreadingâ¯. <br>

**[3] å…³äºå¤šçº¿ç¨‹**
> **(i) ä»€ä¹ˆæ˜¯å¤šçº¿ç¨‹ï¼Ÿ** Multithreading allows the CPU to hold the state of two different threads and then switch back and forth on a nanosecond time scale(CPUä¿å­˜2ä¸ªä¸åŒçš„çº¿ç¨‹çŠ¶æ€ï¼Œå¹¶åœ¨çº³ç§’çº§æ—¶é—´å†…å®ç°åˆ‡æ¢). A thread is a kind of lightweight process, which, in turn, is a running program(çº¿ç¨‹æ˜¯ä¸€ç§è½»é‡çº§è¿›ç¨‹ï¼Œè¿›ç¨‹è¡¨ç¤ºä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„ç¨‹åºï¼Œåœ¨chapter2ä¸­è¿›è¡Œè¯¦ç»†çš„ä»‹ç»). <br>
> **(ii) å¤šçº¿ç¨‹ä¹‹äºæ“ä½œç³»ç»Ÿ** Multithreading has implications for the operating system because each thread appears to the operating system as a separate CPU. Consider a system with two actual CPUs, each with two threads. The operating system will see this as four CPUs.  

**[4] å…³äºå¤šæ ¸èŠ¯ç‰‡**
> Beyond multithreading, many CPU chips now have four, eight, or more complete processors or cores on them. The multicore chips as the following figure effectively carry four minichips on them, each with its own independent CPU. 

<center><img src="/img/in-post/operating_system_img/os_1_4.pdf" width="80%"></center>

> **å¤šæ ¸èŠ¯ç‰‡éœ€è¦å¤šå¤„ç†å™¨æ“ä½œç³»ç»Ÿè¿›è¡Œæ”¯æŒ** Making use of such a multicore chip will definitely require a multiprocessor operating system.
> **ä¸Šå›¾ä¸­çš„intelæ¶æ„å’ŒAMDæ¶æ„å„æœ‰åƒç§‹** Each strategy has its pros and cons. For example, the Intel shared L2 cache requires a more complicated cache controller but the AMD way makes keeping the L2 caches consistent more difficult.

**[5] å…³äºGPU**
> A GPU is a processor with, literally, thousands of tiny cores(å¾®æ ¸å¿ƒ). They are very good for many small computations done in parallel(æ“…é•¿å¤§é‡ç®€å•å¹¶è¡Œè®¡ç®—), like rendering polygons in graphics applications. They are not so good at serial tasks(ä¸æ“…é•¿ä¸²è¡Œä»»åŠ¡). They are also hard to program. <br> 
> While GPUs can be useful for operating systems (e.g., encryption(åŠ å¯†æŠ€æœ¯) or processing of network traffic(å¤„ç†ç½‘ç»œæµé‡)), it is not likely that much of the operating system itself will run on the GPUs(æ“ä½œç³»ç»Ÿæœ¬èº«ä¸å¤ªå¯èƒ½è¿è¡Œåœ¨GPUä¸Š).


###### 4.3 å­˜å‚¨å™¨(memory)
<center><img src="/img/in-post/operating_system_img/os_1_5.pdf" width="80%"></center>

**[1] å…³äºCPUä¸­çš„å¯„å­˜å™¨(register)**
> They are made of the same material as the CPU and are thus just as fast as the CPU. Consequently, there is no delay in accessing them.
> The storage capacity available in them is typically 32 Ã— 32 bits on a 32-bit CPU and 64 Ã— 64 bits on a 64-bit CPU. Programs must manage the registers (i.e., decide what to keep in them) themselves, in software.

**[2] å…³äº"memory wordçš„å®šä¹‰"**
> A group of memory bits in a RAM or ROM block. Ref.[intel.com](https://www.intel.com/content/www/us/en/programmable/quartushelp/17.0/reference/glossary/def_memory_word.htm)ã€‚

**[3] å…³äºé«˜é€Ÿç¼“å­˜(cache memory)**
> **é«˜é€Ÿç¼“å­˜çš„åŸºæœ¬ç»“æ„** Main memory is divided up into cache lines, typically 64 bytes(64Ã—8cache lines), with addresses 0 to 63 in cache line 0, 64 to 127 in cache line 1, and so on. 

> **é«˜é€Ÿç¼“å­˜çš„ä½œç”¨** The most heavily used cache lines are kept in a high-speed cache located inside or very close to the CPU(æ¶æ„è®¾è®¡ä¸Šï¼Œå°†æœ€å¸¸ç”¨çš„çš„cacheé›†æˆåœ¨CPUçš„å†…éƒ¨oræ”¾ç½®åœ¨CPUä¸´è¿‘å¤„). When the program needs to read a memory word, the cache hardware checks to see if the line needed is in the cache(å½“ç¨‹åºéœ€è¦è¯»å–å†…å­˜å­—æ—¶ï¼Œç¼“å­˜ç›¸å…³ç¡¬ä»¶ä¼˜å…ˆåœ¨cacheä¸­æŸ¥æ‰¾è¯¥å­—). If it is, called a cache hit, the request is satisfied from the cache and no memory request is sent over the bus to the main memory(å¦‚æœåœ¨é«˜é€Ÿç¼“å­˜ä¸­æ‰¾åˆ°åˆ™ç§°ä¸ºç¼“å­˜å‘½ä¸­ï¼Œå› è€Œæ— éœ€é€šè¿‡æ€»çº¿å‘é€memory requestï¼Œä»è€Œæå‡CPUè¿è¡Œé€Ÿç‡). 

> **é™åˆ¶é«˜é€Ÿç¼“å­˜å®¹é‡çš„å› ç´ ** Cache memory is limited in size due to its high cost. 

> **é«˜é€Ÿç¼“å­˜çš„è§£å†³çš„é—®é¢˜** **(i)** When to put a new item into the cache. **(ii)** Which cache line to put the new item in. **(iii)** Which item to remove from the cache when a slot is needed. **(iv)** Where to put a newly evicted item(æ–°ç§»é™¤çš„é¡¹ç›®) in the larger memory. 

> **L1é«˜é€Ÿç¼“å­˜** The first level or L1 cache is always inside the CPU and usually feeds decoded instructions into the CPUâ€™s execution engine(L1é«˜é€Ÿç¼“å­˜é€šå¸¸åœ¨CPUå†…éƒ¨ï¼Œç”¨äºä¿å­˜é€å¾€CPUæ‰§è¡Œå¼•æ“çš„æœºå™¨æŒ‡ä»¤). Most chips have a second L1 cache for very heavily used data words(éƒ¨åˆ†èŠ¯ç‰‡æ‹¥æœ‰ç¬¬äºŒå—L1ç¼“å­˜). The L1 caches are typically 16 KB each. <br>
> **L2é«˜é€Ÿç¼“å­˜** In addition, there is often a second cache, called the L2 cache, that holds several megabytes of recently used memory words(L2é«˜é€Ÿç¼“å­˜ç”¨äºä¿å­˜è¿‘æœŸä½¿ç”¨çš„å†…å­˜å­—). <br>
> **L1å’ŒL2é«˜é€Ÿç¼“å­˜ä¹‹é—´çš„åŒºåˆ«** The difference between the L1 and L2 caches lies in the timing. Access to the L1 cache is done without any delay, whereas access to the L2 cache involves a delay of one or two clock cycles.

**[4] å…³äºä¸»å­˜(main memory)** 
> **éšæœºè®¿é—®å­˜å‚¨RAM(volatile)** This is the workhorse(ä¸»åŠ›) of the memory system. Main memory is usually called RAM (Random Access Memory). All CPU requests that cannot be satisfied out of the cache go to main memory.

> **åªè¯»å­˜å‚¨ROM(non-volatile)** Unlike RAM, nonvolatile memory does not lose its contents when the power is switched off(æ–­ç”µåï¼Œéæ˜“å¤±æ€§å­˜å‚¨ä¸ä¼šä¸¢å¤±æ‰€å­˜å‚¨çš„å†…å®¹). ROM (Read Only Memory) is programmed at the factory and cannot be changed afterward(åªè¯»å­˜å‚¨åœ¨ç”Ÿäº§æ—¶çƒ§å…¥ç¨‹åºï¼Œåç»­æ— æ³•ä¿®æ”¹). It is fast and inexpensive. On some computers, the bootstrap loader used to start the computer is contained in ROM(ç³»ç»Ÿå¼•å¯¼loaderå­˜å‚¨åœ¨ROMä¸­). Also, some I/O cards come with ROM for handling low-level device control(IOæ¥å£å¡ä¸­ä¹Ÿæœ‰ä½å±‚æ¬¡çš„ROMç”¨äºè®¾å¤‡æ§åˆ¶).

> **EEPROM & é—ªå­˜(both non-volatile)å’ŒROMçš„åŒºåˆ«** EEPROM (Electrically Erasable Programmable ROM) and flash memory are also non-volatile, but in contrast to ROM can be erased and rewritten. However, writing them takes orders of magnitude more time than writing RAM, so they are used in the same way ROM is, only with the additional feature that it is now possible to correct bugs in programs they hold by rewriting them in the field. <br>
> **é—ªå­˜** Flash memory is also commonly used as the storage medium in portable electronic devices(åœ¨ä¾¿æºå¼ç”µå­è®¾å¤‡ä¸­å¹¿æ³›ä½¿ç”¨). It serves as film in digital cameras(ç”µå­ç›¸æœºèƒ¶å·) and as the disk in portable music players(éšèº«å¬çš„ç£ç›˜), to name just two uses. <br>
> **é—ªå­˜çš„ä¼ è¾“é€Ÿåº¦ & ä½¿ç”¨å¯¿å‘½** Flash memory is intermediate in speed between RAM and disk. Also, unlike disk memory, if it is erased too many times, it wears out.

> **CMOSå­˜å‚¨(volatile)** Yet another kind of memory is CMOS, which is volatile. Many computers use CMOS memory to hold the current time and date. The CMOS memory and the clock circuit that increments the time in it are powered by a small battery(CMOSå­˜å‚¨åŠå…¶æ—¶é’Ÿç”µè·¯ç”±ç”µæ± é©±åŠ¨), so the time is correctly updated, even when the computer is unplugged. The CMOS memory can also hold the configuration parameters, such as which disk to boot from(CMOSå­˜å‚¨åŒ…æ‹¬ä¸€äº›é…ç½®ä¿¡æ¯e.g.ç³»ç»Ÿä»å“ªä¸ªç£ç›˜å¯åŠ¨).

**[5] å…³äºç£ç›˜(disk)** <br>
> **æœºæ¢°ç£ç›˜å’ŒRAMä¹‹é—´çš„è®¿é—®é€Ÿç‡ & å®¹é‡å¯¹æ¯”** Disk storage is two orders of magnitude cheaper than RAM per bit and often two orders of magnitude larger as well. The only problem is that the time to randomly access data on it is close to three orders of magnitude slower. The reason is that a disk is a mechanical device.

<center><img src="/img/in-post/operating_system_img/os_1_6.pdf" width="100%"></center>

> **æœºæ¢°ç£ç›˜è¯»å–è®¿é—®å ç”¨æ—¶é—´åˆ†æ** **(i)** Moving the arm from one cylinder to the next takes about 1 msec. **(ii)** Moving it to a random cylinder typically takes 5 to 10 msec, depending on the drive. **(iii)** Once the arm is on the correct track, the drive must wait for the needed sector to rotate under the head, an additional delay of 5 msec to 10 msec, depending on the driveâ€™s RPM. **(iv)** Once the sector is under the head, reading or writing occurs at a rate of 50 MB/sec on low-end disks to 160 MB/sec on faster ones.

> **å›ºæ€ç¡¬ç›˜** SSDs(Solid State Disks) are really not disks at all. SSDs do not have moving parts, do not contain platters in the shape of disks, and store data in (Flash) memory. The only ways in which they resemble disks is that they also store a lot of data which is not lost when the power is off.

> **ç®€ä»‹è™šæ‹Ÿå†…å­˜æŠ€æœ¯** Many computers support a scheme known as virtual memory. This scheme makes it possible to run programs larger than physical memory by placing them on the disk and using main memory as a kind of cache for the most heavily executed parts(å°†ç‰©ç†å†…å­˜æ˜ å°„åˆ°ç£ç›˜ä¸Šï¼Œå¹¶å°†ä¸»å­˜ä½œä¸ºç¨‹åºé¢‘ç¹æ‰§è¡Œéƒ¨åˆ†æ‰€éœ€çš„"é«˜é€Ÿç¼“å­˜"). <br>
> **å†…å­˜å¤„ç†å•å…ƒè´Ÿè´£æ‰§è¡Œè¿™ç§"é£é€Ÿ"åœ°å€æ˜ å°„** This scheme requires remapping memory addresses on the fly to convert the address the program generated to the physical address in RAM where the word is located. This mapping is done by a part of the CPU called the MMU (Memory Management Unit).

> **æµ…è°ˆåº”ç”¨ç¨‹åºä¸Šä¸‹æ–‡åˆ‡æ¢** The presence of caching and the MMU can have a major impact on performance(å†…å­˜å¤„ç†å•å…ƒå’Œç¼“å­˜æŠ€æœ¯å¯¹äºç¨‹åºæ€§èƒ½å½±å“æ·±è¿œ). In a multiprogramming system, when switching from one program to another, sometimes called a **context switch**, it may be necessary to flush all modified blocks from the cache and change the mapping registers in the MMU(ä¸ºäº†å®ç°è¿™ç§åº”ç”¨åˆ‡æ¢ï¼Œå¯èƒ½éœ€è¦å°†é«˜é€Ÿç¼“å­˜ä¸­æ‰€æœ‰è¢«åº”ç”¨ä¿®æ”¹çš„åŒºå—æ‰§è¡Œåˆ·æ–°æ“ä½œï¼Œå¹¶ä¿®æ”¹MMUä¸­åº”ç”¨çš„æ˜ å°„å¯„å­˜å™¨æ•°å€¼). Both of these are expensive operations, and programmers try hard to avoid them(ä¸Šè¿°æ“ä½œä»£ä»·å¾ˆé«˜). 

###### 4.4 I/Oè®¾å¤‡  


## Reference
> \<modern operating system 4th\> chapter1 <br>

> 1 å½“ä½¿ç”¨inlineæ•°å­¦å…¬å¼ä¸”å…¬å¼ç»è¿‡GFMæ’ç‰ˆä¹‹åéƒ½åœ¨åŒä¸€è¡Œ ä½¿ç”¨`$...$`ç¬¦å·<br>
> 2 å½“å¸Œæœ›æ•°å­¦å…¬å¼å•ç‹¬æˆè¡Œæˆ–è€…ç»è¿‡GFMæ’ç‰ˆä¹‹åå ç”¨å¤šè¡Œ åº”å½“ä½¿ç”¨`$$...$$`ç¬¦å·<br>
> 3 å¯¹äºè¡¨ç¤ºæ¡ä»¶æ¦‚ç‡ éœ€è¦è¡¨ç¤ºç«–çº¿çš„æ—¶å€™`|` åº”å½“ä½¿ç”¨`\mid` è€Œä¸æ˜¯ç›´æ¥åœ¨é”®ç›˜ä¸Šæ‰“å‡º`|` => å®¹æ˜“è¢«ç¼–è¾‘å™¨è®¤ä¸ºæ˜¯ä¸€ä¸ªmdåˆ¶è¡¨ç¬¦<br>
> 4 åœ¨mdå¼•å…¥å›¾ç‰‡çš„æ—¶å€™ ä¸è¦ä½¿ç”¨`<center>`å’Œ`</center>` åœ¨è¿™ç¯‡æ–‡æ¡£çš„ç¼–è¾‘è¿‡ç¨‹ä¸­vscodeçš„previewæ’ä»¶åœ¨ä½¿ç”¨äº†ä¸Šè¿°ç¬¦å·ä¹‹å å¯¼è‡´ä¸‹ä¸€æ®µçš„æ•°å­¦å…¬å¼é¢„è§ˆæ˜¾ç¤ºä¸æ­£å¸¸<br>
> 5 ä½¿ç”¨mdçš„æ—¶å€™ å•ç‹¬çš„ä¸¤æ®µæ–‡å­—ä¸Šä¸‹éœ€è¦ç©ºå‡ºä¸€è¡Œ<br>
> 6 æƒ³è¦å¼ºåˆ¶æ¢è¡Œçš„æ—¶å€™ éœ€è¦ä½¿ç”¨`<br>`è€Œä¸æ˜¯`<enter>`<br>
> 7 ç‰¹æ®Šå­—ç¬¦å¦‚æœæƒ³è¦é¿å…å’Œmdè§£æå…³é”®å­—å†²çª åº”å½“ä½¿ç”¨\`\`å°†å…³é”®å­—åŒ…å«åœ¨å†… <br>
> 8 `<center><img src="/img/in-post/economics_4/xxx.png" width="60%"></center>` <br>
> 9 ä½¿ç”¨htmlè®¾ç½®å›¾ç‰‡æ–‡å­—ç¯ç»•æ–¹å¼ï¼š<br>
    `<div>` <br>
        `<img src="/img_path" align="left" width="40%" hspace="" vspace=""/>` <br>
        `<p>paragraph1 around the picture</p>` <br>
        `<p>paragraph2 around the picture</p>` <br>
        `<p>paragraph3 around the picture</p>` <br>
    `</div>` <br>
> 10 `<font style="color:red; font-weight:bold">åŠ ç²—è“è‰²</font>`ç”¨æ¥è®¾ç½®å­—ä½“é¢œè‰² <br>
> 11 ä½¿ç”¨htmlè®¾ç½®å¯æŠ˜å éƒ¨åˆ†å†…å®¹ï¼š<br>
  `<details>` <br>
      `<summary><b>[ç‚¹å‡»å±•å¼€] xxx</b></summary>` <br>
      `<center><img src="/img/in-post/tcp-ip_img/tcp_20_9.pdf" width="100%"></center>` <br>
  `</details>` <br>
> 12 é—®é¢˜è„šæ³¨: ???problemğŸ˜«problem???
